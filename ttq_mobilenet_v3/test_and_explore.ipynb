{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Me Looking at the Model Features (also for investigating layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from mobilenet_v3 import MobileNetV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MobileNetV3(n_class=200, input_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on MobileNetV3 in module mobilenet_v3 object:\n",
      "\n",
      "class MobileNetV3(torch.nn.modules.module.Module)\n",
      " |  Base class for all neural network modules.\n",
      " |  \n",
      " |  Your models should also subclass this class.\n",
      " |  \n",
      " |  Modules can also contain other Modules, allowing to nest them in\n",
      " |  a tree structure. You can assign the submodules as regular attributes::\n",
      " |  \n",
      " |      import torch.nn as nn\n",
      " |      import torch.nn.functional as F\n",
      " |  \n",
      " |      class Model(nn.Module):\n",
      " |          def __init__(self):\n",
      " |              super(Model, self).__init__()\n",
      " |              self.conv1 = nn.Conv2d(1, 20, 5)\n",
      " |              self.conv2 = nn.Conv2d(20, 20, 5)\n",
      " |  \n",
      " |          def forward(self, x):\n",
      " |              x = F.relu(self.conv1(x))\n",
      " |              return F.relu(self.conv2(x))\n",
      " |  \n",
      " |  Submodules assigned in this way will be registered, and will have their\n",
      " |  parameters converted too when you call :meth:`to`, etc.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MobileNetV3\n",
      " |      torch.nn.modules.module.Module\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_class=1000, input_size=224, dropout=0.8, mode='small', width_mult=1.0)\n",
      " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
      " |  \n",
      " |  forward(self, x)\n",
      " |      Defines the computation performed at every call.\n",
      " |      \n",
      " |      Should be overridden by all subclasses.\n",
      " |      \n",
      " |      .. note::\n",
      " |          Although the recipe for forward pass needs to be defined within\n",
      " |          this function, one should call the :class:`Module` instance afterwards\n",
      " |          instead of this since the former takes care of running the\n",
      " |          registered hooks while the latter silently ignores them.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __call__(self, *input, **kwargs)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __dir__(self)\n",
      " |      __dir__() -> list\n",
      " |      default dir() implementation\n",
      " |  \n",
      " |  __getattr__(self, name)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_module(self, name, module)\n",
      " |      Adds a child module to the current module.\n",
      " |      \n",
      " |      The module can be accessed as an attribute using the given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the child module. The child module can be\n",
      " |              accessed from this module using the given name\n",
      " |          module (Module): child module to be added to the module.\n",
      " |  \n",
      " |  apply(self, fn)\n",
      " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
      " |      as well as self. Typical use includes initializing the parameters of a model\n",
      " |      (see also :ref:`nn-init-doc`).\n",
      " |      \n",
      " |      Args:\n",
      " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> def init_weights(m):\n",
      " |          >>>     print(m)\n",
      " |          >>>     if type(m) == nn.Linear:\n",
      " |          >>>         m.weight.data.fill_(1.0)\n",
      " |          >>>         print(m.weight)\n",
      " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
      " |          >>> net.apply(init_weights)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 1.,  1.],\n",
      " |                  [ 1.,  1.]])\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |  \n",
      " |  buffers(self, recurse=True)\n",
      " |      Returns an iterator over module buffers.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          torch.Tensor: module buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for buf in model.buffers():\n",
      " |          >>>     print(type(buf.data), buf.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  children(self)\n",
      " |      Returns an iterator over immediate children modules.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a child module\n",
      " |  \n",
      " |  cpu(self)\n",
      " |      Moves all model parameters and buffers to the CPU.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  cuda(self, device=None)\n",
      " |      Moves all model parameters and buffers to the GPU.\n",
      " |      \n",
      " |      This also makes associated parameters and buffers different objects. So\n",
      " |      it should be called before constructing optimizer if the module will\n",
      " |      live on GPU while being optimized.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          device (int, optional): if specified, all parameters will be\n",
      " |              copied to that device\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  double(self)\n",
      " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  eval(self)\n",
      " |      Sets the module in evaluation mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  extra_repr(self)\n",
      " |      Set the extra representation of the module\n",
      " |      \n",
      " |      To print customized extra information, you should reimplement\n",
      " |      this method in your own modules. Both single-line and multi-line\n",
      " |      strings are acceptable.\n",
      " |  \n",
      " |  float(self)\n",
      " |      Casts all floating point parameters and buffers to float datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  half(self)\n",
      " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  load_state_dict(self, state_dict, strict=True)\n",
      " |      Copies parameters and buffers from :attr:`state_dict` into\n",
      " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
      " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
      " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          state_dict (dict): a dict containing parameters and\n",
      " |              persistent buffers.\n",
      " |          strict (bool, optional): whether to strictly enforce that the keys\n",
      " |              in :attr:`state_dict` match the keys returned by this module's\n",
      " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
      " |      \n",
      " |      Returns:\n",
      " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
      " |              * **missing_keys** is a list of str containing the missing keys\n",
      " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
      " |  \n",
      " |  modules(self)\n",
      " |      Returns an iterator over all modules in the network.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Module: a module in the network\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          )\n",
      " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
      " |  \n",
      " |  named_buffers(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module buffers, yielding both the\n",
      " |      name of the buffer as well as the buffer itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all buffer names.\n",
      " |          recurse (bool): if True, then yields buffers of this module\n",
      " |              and all submodules. Otherwise, yields only buffers that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, buf in self.named_buffers():\n",
      " |          >>>    if name in ['running_var']:\n",
      " |          >>>        print(buf.size())\n",
      " |  \n",
      " |  named_children(self)\n",
      " |      Returns an iterator over immediate children modules, yielding both\n",
      " |      the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple containing a name and child module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, module in model.named_children():\n",
      " |          >>>     if name in ['conv4', 'conv5']:\n",
      " |          >>>         print(module)\n",
      " |  \n",
      " |  named_modules(self, memo=None, prefix='')\n",
      " |      Returns an iterator over all modules in the network, yielding\n",
      " |      both the name of the module as well as the module itself.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Module): Tuple of name and module\n",
      " |      \n",
      " |      Note:\n",
      " |          Duplicate modules are returned only once. In the following\n",
      " |          example, ``l`` will be returned only once.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> l = nn.Linear(2, 2)\n",
      " |          >>> net = nn.Sequential(l, l)\n",
      " |          >>> for idx, m in enumerate(net.named_modules()):\n",
      " |                  print(idx, '->', m)\n",
      " |      \n",
      " |          0 -> ('', Sequential(\n",
      " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
      " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
      " |          ))\n",
      " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
      " |  \n",
      " |  named_parameters(self, prefix='', recurse=True)\n",
      " |      Returns an iterator over module parameters, yielding both the\n",
      " |      name of the parameter as well as the parameter itself.\n",
      " |      \n",
      " |      Args:\n",
      " |          prefix (str): prefix to prepend to all parameter names.\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          (string, Parameter): Tuple containing the name and parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for name, param in self.named_parameters():\n",
      " |          >>>    if name in ['bias']:\n",
      " |          >>>        print(param.size())\n",
      " |  \n",
      " |  parameters(self, recurse=True)\n",
      " |      Returns an iterator over module parameters.\n",
      " |      \n",
      " |      This is typically passed to an optimizer.\n",
      " |      \n",
      " |      Args:\n",
      " |          recurse (bool): if True, then yields parameters of this module\n",
      " |              and all submodules. Otherwise, yields only parameters that\n",
      " |              are direct members of this module.\n",
      " |      \n",
      " |      Yields:\n",
      " |          Parameter: module parameter\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> for param in model.parameters():\n",
      " |          >>>     print(type(param.data), param.size())\n",
      " |          <class 'torch.FloatTensor'> (20L,)\n",
      " |          <class 'torch.FloatTensor'> (20L, 1L, 5L, 5L)\n",
      " |  \n",
      " |  register_backward_hook(self, hook)\n",
      " |      Registers a backward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time the gradients with respect to module\n",
      " |      inputs are computed. The hook should have the following signature::\n",
      " |      \n",
      " |          hook(module, grad_input, grad_output) -> Tensor or None\n",
      " |      \n",
      " |      The :attr:`grad_input` and :attr:`grad_output` may be tuples if the\n",
      " |      module has multiple inputs or outputs. The hook should not modify its\n",
      " |      arguments, but it can optionally return a new gradient with respect to\n",
      " |      input that will be used in place of :attr:`grad_input` in subsequent\n",
      " |      computations.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |      \n",
      " |      .. warning ::\n",
      " |      \n",
      " |          The current implementation will not have the presented behavior\n",
      " |          for complex :class:`Module` that perform many operations.\n",
      " |          In some failure cases, :attr:`grad_input` and :attr:`grad_output` will only\n",
      " |          contain the gradients for a subset of the inputs and outputs.\n",
      " |          For such :class:`Module`, you should use :func:`torch.Tensor.register_hook`\n",
      " |          directly on a specific input or output to get the required gradients.\n",
      " |  \n",
      " |  register_buffer(self, name, tensor)\n",
      " |      Adds a persistent buffer to the module.\n",
      " |      \n",
      " |      This is typically used to register a buffer that should not to be\n",
      " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
      " |      is not a parameter, but is part of the persistent state.\n",
      " |      \n",
      " |      Buffers can be accessed as attributes using given names.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the buffer. The buffer can be accessed\n",
      " |              from this module using the given name\n",
      " |          tensor (Tensor): buffer to be registered.\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
      " |  \n",
      " |  register_forward_hook(self, hook)\n",
      " |      Registers a forward hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time after :func:`forward` has computed an output.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input, output) -> None or modified output\n",
      " |      \n",
      " |      The hook can modify the output. It can modify the input inplace but\n",
      " |      it will not have effect on forward since this is called after\n",
      " |      :func:`forward` is called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_forward_pre_hook(self, hook)\n",
      " |      Registers a forward pre-hook on the module.\n",
      " |      \n",
      " |      The hook will be called every time before :func:`forward` is invoked.\n",
      " |      It should have the following signature::\n",
      " |      \n",
      " |          hook(module, input) -> None or modified input\n",
      " |      \n",
      " |      The hook can modify the input. User can either return a tuple or a\n",
      " |      single modified value in the hook. We will wrap the value into a tuple\n",
      " |      if a single value is returned(unless that value is already a tuple).\n",
      " |      \n",
      " |      Returns:\n",
      " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
      " |              a handle that can be used to remove the added hook by calling\n",
      " |              ``handle.remove()``\n",
      " |  \n",
      " |  register_parameter(self, name, param)\n",
      " |      Adds a parameter to the module.\n",
      " |      \n",
      " |      The parameter can be accessed as an attribute using given name.\n",
      " |      \n",
      " |      Args:\n",
      " |          name (string): name of the parameter. The parameter can be accessed\n",
      " |              from this module using the given name\n",
      " |          param (Parameter): parameter to be added to the module.\n",
      " |  \n",
      " |  requires_grad_(self, requires_grad=True)\n",
      " |      Change if autograd should record operations on parameters in this\n",
      " |      module.\n",
      " |      \n",
      " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
      " |      in-place.\n",
      " |      \n",
      " |      This method is helpful for freezing part of the module for finetuning\n",
      " |      or training parts of a model individually (e.g., GAN training).\n",
      " |      \n",
      " |      Args:\n",
      " |          requires_grad (bool): whether autograd should record operations on\n",
      " |                                parameters in this module. Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  share_memory(self)\n",
      " |  \n",
      " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
      " |      Returns a dictionary containing a whole state of the module.\n",
      " |      \n",
      " |      Both parameters and persistent buffers (e.g. running averages) are\n",
      " |      included. Keys are corresponding parameter and buffer names.\n",
      " |      \n",
      " |      Returns:\n",
      " |          dict:\n",
      " |              a dictionary containing a whole state of the module\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> module.state_dict().keys()\n",
      " |          ['bias', 'weight']\n",
      " |  \n",
      " |  to(self, *args, **kwargs)\n",
      " |      Moves and/or casts the parameters and buffers.\n",
      " |      \n",
      " |      This can be called as\n",
      " |      \n",
      " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(dtype, non_blocking=False)\n",
      " |      \n",
      " |      .. function:: to(tensor, non_blocking=False)\n",
      " |      \n",
      " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
      " |      floating point desired :attr:`dtype` s. In addition, this method will\n",
      " |      only cast the floating point parameters and buffers to :attr:`dtype`\n",
      " |      (if given). The integral parameters and buffers will be moved\n",
      " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
      " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
      " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
      " |      pinned memory to CUDA devices.\n",
      " |      \n",
      " |      See below for examples.\n",
      " |      \n",
      " |      .. note::\n",
      " |          This method modifies the module in-place.\n",
      " |      \n",
      " |      Args:\n",
      " |          device (:class:`torch.device`): the desired device of the parameters\n",
      " |              and buffers in this module\n",
      " |          dtype (:class:`torch.dtype`): the desired floating point type of\n",
      " |              the floating point parameters and buffers in this module\n",
      " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
      " |              dtype and device for all parameters and buffers in this module\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |      \n",
      " |      Example::\n",
      " |      \n",
      " |          >>> linear = nn.Linear(2, 2)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]])\n",
      " |          >>> linear.to(torch.double)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1913, -0.3420],\n",
      " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
      " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
      " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
      " |          >>> cpu = torch.device(\"cpu\")\n",
      " |          >>> linear.to(cpu)\n",
      " |          Linear(in_features=2, out_features=2, bias=True)\n",
      " |          >>> linear.weight\n",
      " |          Parameter containing:\n",
      " |          tensor([[ 0.1914, -0.3420],\n",
      " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
      " |  \n",
      " |  train(self, mode=True)\n",
      " |      Sets the module in training mode.\n",
      " |      \n",
      " |      This has any effect only on certain modules. See documentations of\n",
      " |      particular modules for details of their behaviors in training/evaluation\n",
      " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
      " |      etc.\n",
      " |      \n",
      " |      Args:\n",
      " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
      " |                       mode (``False``). Default: ``True``.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  type(self, dst_type)\n",
      " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          dst_type (type or string): the desired type\n",
      " |      \n",
      " |      Returns:\n",
      " |          Module: self\n",
      " |  \n",
      " |  zero_grad(self)\n",
      " |      Sets gradients of all model parameters to zero.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
      " |  \n",
      " |  dump_patches = False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features[14].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Hswish()\n",
       "  )\n",
       "  (1): MobileBottleneck(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "      (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=4, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=4, out_features=16, bias=False)\n",
       "          (3): Hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (8): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (2): MobileBottleneck(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "      (4): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Identity()\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (3): MobileBottleneck(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "      (4): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Identity()\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (8): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (4): MobileBottleneck(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Hswish()\n",
       "      (3): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "      (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=96, out_features=24, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=24, out_features=96, bias=False)\n",
       "          (3): Hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (6): Hswish()\n",
       "      (7): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (5): MobileBottleneck(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Hswish()\n",
       "      (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "      (4): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=240, out_features=60, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=60, out_features=240, bias=False)\n",
       "          (3): Hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (6): Hswish()\n",
       "      (7): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (6): MobileBottleneck(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Hswish()\n",
       "      (3): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "      (4): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=240, out_features=60, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=60, out_features=240, bias=False)\n",
       "          (3): Hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (6): Hswish()\n",
       "      (7): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (8): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (7): MobileBottleneck(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Hswish()\n",
       "      (3): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "      (4): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=120, out_features=30, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=30, out_features=120, bias=False)\n",
       "          (3): Hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (6): Hswish()\n",
       "      (7): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (8): MobileBottleneck(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Hswish()\n",
       "      (3): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "      (4): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=144, out_features=36, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=36, out_features=144, bias=False)\n",
       "          (3): Hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (6): Hswish()\n",
       "      (7): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (8): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (9): MobileBottleneck(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Hswish()\n",
       "      (3): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "      (4): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=288, out_features=72, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=72, out_features=288, bias=False)\n",
       "          (3): Hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (6): Hswish()\n",
       "      (7): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (10): MobileBottleneck(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Hswish()\n",
       "      (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "      (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=576, out_features=144, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=144, out_features=576, bias=False)\n",
       "          (3): Hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (6): Hswish()\n",
       "      (7): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (11): MobileBottleneck(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Hswish()\n",
       "      (3): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "      (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): SEModule(\n",
       "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=576, out_features=144, bias=False)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=144, out_features=576, bias=False)\n",
       "          (3): Hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (6): Hswish()\n",
       "      (7): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (12): Sequential(\n",
       "    (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Hswish()\n",
       "  )\n",
       "  (13): AdaptiveAvgPool2d(output_size=1)\n",
       "  (14): Conv2d(576, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (15): Hswish()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_parameters at 0x0000020F8B6B3DB0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('features.0.0.weight', Parameter containing:\n",
      "tensor([[[[ 2.9301e-02, -9.8357e-02, -5.8738e-02],\n",
      "          [ 4.4233e-02, -1.2989e-01,  2.6824e-01],\n",
      "          [-7.4594e-02,  3.3319e-02, -9.6873e-02]],\n",
      "\n",
      "         [[ 1.2393e-02, -4.4678e-02,  2.0089e-01],\n",
      "          [-2.7707e-01, -1.7870e-02,  8.3216e-02],\n",
      "          [ 3.5573e-02,  5.1634e-02, -5.6228e-02]],\n",
      "\n",
      "         [[-2.7073e-03, -1.2383e-01, -1.8989e-01],\n",
      "          [ 8.1294e-02, -2.1419e-01,  1.7086e-01],\n",
      "          [-1.8902e-01, -7.0541e-02, -1.5845e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.5371e-02, -2.8984e-02, -1.2668e-01],\n",
      "          [ 8.8808e-02, -4.5659e-02, -7.3812e-03],\n",
      "          [ 6.1884e-04, -5.6829e-02, -5.0865e-02]],\n",
      "\n",
      "         [[-8.0903e-02,  7.7929e-02,  2.9573e-01],\n",
      "          [-5.5195e-02, -1.3692e-02, -3.5968e-02],\n",
      "          [-1.5444e-01,  2.5827e-01,  6.5936e-02]],\n",
      "\n",
      "         [[ 4.2589e-02, -6.2481e-02, -1.7567e-01],\n",
      "          [ 1.9979e-01,  1.9205e-02,  7.8636e-02],\n",
      "          [ 4.1861e-02, -6.9794e-02,  1.8159e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4591e-01,  1.3115e-01, -1.7243e-01],\n",
      "          [ 3.3984e-02, -3.0835e-02, -8.2978e-02],\n",
      "          [ 2.2433e-01,  1.9773e-01,  1.8974e-02]],\n",
      "\n",
      "         [[-1.7087e-01,  7.9238e-03, -1.9787e-01],\n",
      "          [-2.3131e-01,  2.2393e-01, -4.1062e-02],\n",
      "          [-1.6576e-01,  1.0205e-01,  1.8362e-01]],\n",
      "\n",
      "         [[-1.2202e-01,  7.1165e-02,  4.1175e-02],\n",
      "          [ 4.3601e-02,  1.5353e-01,  4.8339e-02],\n",
      "          [ 8.3821e-02, -1.8564e-01, -6.9031e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5954e-03, -9.2985e-02,  2.3586e-03],\n",
      "          [-6.5708e-02,  1.3134e-01, -3.1830e-02],\n",
      "          [-1.5198e-01,  7.3456e-03, -7.0949e-02]],\n",
      "\n",
      "         [[ 3.4787e-02, -2.5103e-02,  1.0668e-01],\n",
      "          [-4.8607e-02, -2.9612e-02, -2.1955e-01],\n",
      "          [ 9.3531e-02, -7.1272e-02,  1.4880e-01]],\n",
      "\n",
      "         [[-1.4559e-01,  2.4352e-01,  6.5655e-02],\n",
      "          [-1.0781e-01, -2.1170e-01, -1.0808e-01],\n",
      "          [-7.8129e-02, -8.7472e-02,  7.4521e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.5138e-02,  1.4560e-01,  1.0248e-01],\n",
      "          [ 1.5130e-01,  6.5506e-02, -7.5959e-02],\n",
      "          [-5.5962e-02,  5.8886e-02,  3.3898e-02]],\n",
      "\n",
      "         [[ 1.8025e-02, -5.0380e-02, -6.8226e-02],\n",
      "          [-2.0310e-01, -1.0675e-01, -3.8192e-02],\n",
      "          [-1.6752e-01, -1.5574e-02,  9.3968e-02]],\n",
      "\n",
      "         [[ 6.3914e-02, -2.1843e-01, -6.8825e-02],\n",
      "          [ 2.6539e-02, -3.1569e-02,  2.1981e-01],\n",
      "          [-1.0037e-01, -1.0149e-01,  1.3165e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.6164e-02, -8.7200e-02,  1.6285e-01],\n",
      "          [ 5.9608e-02, -1.8571e-01,  5.9792e-02],\n",
      "          [-7.7506e-02, -8.5928e-02,  1.4204e-01]],\n",
      "\n",
      "         [[ 1.1070e-01, -1.4062e-01, -1.9831e-01],\n",
      "          [-8.1496e-02,  8.4614e-02, -5.4656e-02],\n",
      "          [ 2.2534e-02,  2.0381e-01,  1.2361e-01]],\n",
      "\n",
      "         [[ 1.1313e-01,  9.3580e-03,  3.4761e-01],\n",
      "          [ 8.2543e-02,  3.2314e-02, -1.4337e-01],\n",
      "          [-6.7336e-02,  8.1121e-02, -2.8495e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3874e-03, -5.4914e-02,  6.6705e-02],\n",
      "          [-3.9072e-01, -2.4420e-01,  1.1202e-01],\n",
      "          [ 1.4065e-01, -2.6450e-02, -2.2615e-01]],\n",
      "\n",
      "         [[ 1.4534e-01, -7.4734e-02,  1.8509e-01],\n",
      "          [-5.1787e-02, -1.2066e-01, -1.3364e-01],\n",
      "          [ 2.1391e-01,  1.8150e-01, -1.1823e-01]],\n",
      "\n",
      "         [[ 5.4314e-02, -6.4053e-02,  1.1554e-01],\n",
      "          [-1.9167e-01, -1.3828e-01, -1.0375e-03],\n",
      "          [-9.0641e-02, -2.0609e-02,  6.2013e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3712e-02,  3.1387e-02, -7.5417e-02],\n",
      "          [ 1.1760e-01, -4.2970e-02,  2.3006e-01],\n",
      "          [ 1.6490e-02, -3.4816e-02,  3.8627e-02]],\n",
      "\n",
      "         [[-6.0660e-03, -5.1366e-02, -9.5182e-03],\n",
      "          [-1.1535e-01, -6.0219e-02,  8.1658e-02],\n",
      "          [ 2.2946e-01, -9.3912e-02, -7.1513e-02]],\n",
      "\n",
      "         [[ 1.8072e-01,  9.7476e-02, -1.7468e-01],\n",
      "          [ 2.2253e-01,  8.0530e-02, -1.0604e-01],\n",
      "          [ 9.1944e-03, -1.8636e-01,  9.0267e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4239e-02,  3.3945e-02, -1.5473e-01],\n",
      "          [-2.1683e-02,  1.5029e-01,  8.1870e-02],\n",
      "          [-5.1509e-03, -8.9686e-02, -1.6718e-01]],\n",
      "\n",
      "         [[ 1.7589e-01, -6.2514e-03,  3.6642e-02],\n",
      "          [ 1.8808e-02, -3.8754e-02,  2.3377e-02],\n",
      "          [-5.4093e-02, -1.3627e-01,  1.9091e-02]],\n",
      "\n",
      "         [[ 8.1891e-02,  2.9899e-02, -9.9983e-02],\n",
      "          [ 9.5600e-02,  1.3840e-01,  1.1144e-01],\n",
      "          [ 1.1691e-01,  2.2396e-01,  1.2184e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5288e-01,  4.8575e-02, -4.8533e-02],\n",
      "          [ 6.9531e-02,  2.2044e-01, -7.2508e-02],\n",
      "          [ 3.6843e-02, -4.3112e-02, -4.3430e-02]],\n",
      "\n",
      "         [[-5.6085e-02, -1.0764e-01,  1.4602e-01],\n",
      "          [-2.0104e-01,  4.5422e-02,  2.7574e-02],\n",
      "          [ 9.0197e-02, -5.7039e-02,  2.1003e-01]],\n",
      "\n",
      "         [[ 1.8953e-02, -9.0400e-03, -1.1557e-02],\n",
      "          [-1.5629e-01, -5.9742e-02,  8.3400e-02],\n",
      "          [ 3.1486e-01,  2.5789e-01, -2.0154e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.7862e-02, -4.5065e-02, -7.0990e-02],\n",
      "          [-1.4134e-02,  9.5947e-02,  1.7769e-01],\n",
      "          [ 2.4614e-01, -3.0595e-01,  1.4367e-02]],\n",
      "\n",
      "         [[ 4.6663e-02, -9.0755e-02,  2.9064e-02],\n",
      "          [-8.0620e-03,  5.3744e-02, -1.7078e-01],\n",
      "          [-2.7554e-01, -9.4221e-02,  1.9498e-01]],\n",
      "\n",
      "         [[-2.8392e-02, -2.3023e-01, -1.1582e-01],\n",
      "          [ 5.8943e-02,  2.4866e-02,  8.7757e-02],\n",
      "          [-1.9901e-01, -1.7363e-01,  4.9063e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.7684e-02, -1.2480e-02, -7.1262e-02],\n",
      "          [ 1.8855e-01, -1.6378e-01, -5.6055e-02],\n",
      "          [ 2.2775e-02, -4.8845e-02,  2.8032e-02]],\n",
      "\n",
      "         [[-7.8919e-02,  7.5923e-02, -2.6360e-02],\n",
      "          [-7.2389e-02,  1.8239e-01,  1.5802e-01],\n",
      "          [-4.9851e-02,  1.4718e-01,  7.5924e-02]],\n",
      "\n",
      "         [[-1.0580e-01, -1.5192e-01, -1.2697e-01],\n",
      "          [-2.8419e-03,  1.0070e-01, -7.0575e-03],\n",
      "          [ 1.6708e-01,  1.0597e-01,  7.5209e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8803e-02,  2.6104e-02, -1.0030e-01],\n",
      "          [ 8.2334e-02, -2.5148e-02,  1.6814e-01],\n",
      "          [-2.7248e-02, -5.3707e-02, -4.6394e-02]],\n",
      "\n",
      "         [[ 4.6193e-03,  2.0767e-01, -1.1150e-01],\n",
      "          [-1.5709e-02,  1.1687e-01,  7.1165e-02],\n",
      "          [-8.0178e-03,  3.7910e-02, -1.7272e-01]],\n",
      "\n",
      "         [[-2.5416e-01, -3.7122e-02, -1.0450e-01],\n",
      "          [-2.2896e-02,  3.0194e-02,  4.8233e-02],\n",
      "          [ 1.1235e-01,  6.2860e-03, -1.9365e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8326e-03, -1.0449e-01,  6.5560e-02],\n",
      "          [ 9.6157e-03, -1.0452e-01,  6.8782e-02],\n",
      "          [ 2.7037e-02,  6.7898e-02, -4.3972e-03]],\n",
      "\n",
      "         [[ 8.2653e-02, -9.7745e-02, -4.3765e-03],\n",
      "          [-8.6877e-02, -1.1178e-01,  1.5489e-01],\n",
      "          [-1.5917e-01, -4.3005e-03, -2.0024e-02]],\n",
      "\n",
      "         [[-7.1279e-02,  4.8207e-02,  1.0855e-01],\n",
      "          [ 1.6623e-03, -1.1561e-01,  7.0686e-02],\n",
      "          [-1.6750e-01, -1.8086e-01,  4.8172e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1066e-02,  1.8769e-01,  1.1675e-01],\n",
      "          [-2.4343e-01, -3.0047e-02, -9.6897e-02],\n",
      "          [-2.7248e-01, -1.0440e-01,  1.0908e-02]],\n",
      "\n",
      "         [[-1.0189e-01, -9.5841e-02, -6.4906e-02],\n",
      "          [ 1.4895e-01,  1.3351e-01,  8.5662e-02],\n",
      "          [ 8.0106e-02,  1.3164e-01, -2.0587e-01]],\n",
      "\n",
      "         [[ 7.5592e-02, -2.0980e-01, -1.2793e-01],\n",
      "          [-1.2921e-02, -4.0782e-02,  2.1429e-01],\n",
      "          [ 1.9044e-02,  1.1023e-01,  8.7672e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2549e-02, -6.4906e-02,  9.2485e-02],\n",
      "          [ 9.4748e-02,  1.3529e-01,  7.5378e-02],\n",
      "          [-1.5566e-01,  6.2869e-02, -1.4578e-02]],\n",
      "\n",
      "         [[-2.3986e-02,  1.0869e-01, -3.8224e-04],\n",
      "          [ 6.4926e-02,  7.1514e-03, -2.8838e-02],\n",
      "          [ 1.4464e-01, -1.3748e-01,  1.9119e-01]],\n",
      "\n",
      "         [[-1.2295e-01,  3.3426e-02, -2.1166e-01],\n",
      "          [-4.9260e-02,  1.2318e-01,  1.2370e-02],\n",
      "          [ 1.3321e-01, -4.2419e-02,  3.2026e-02]]]], requires_grad=True))\n",
      "('features.0.1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.0.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.1.conv.0.weight', Parameter containing:\n",
      "tensor([[[[ 0.5576]],\n",
      "\n",
      "         [[-0.5645]],\n",
      "\n",
      "         [[-0.2339]],\n",
      "\n",
      "         [[ 0.2788]],\n",
      "\n",
      "         [[ 0.2906]],\n",
      "\n",
      "         [[ 0.4464]],\n",
      "\n",
      "         [[-0.0521]],\n",
      "\n",
      "         [[ 0.4013]],\n",
      "\n",
      "         [[ 0.2426]],\n",
      "\n",
      "         [[ 0.4982]],\n",
      "\n",
      "         [[ 0.3959]],\n",
      "\n",
      "         [[-0.0016]],\n",
      "\n",
      "         [[ 0.5885]],\n",
      "\n",
      "         [[-0.2802]],\n",
      "\n",
      "         [[ 0.3369]],\n",
      "\n",
      "         [[ 0.0707]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4307]],\n",
      "\n",
      "         [[ 0.0586]],\n",
      "\n",
      "         [[ 0.3421]],\n",
      "\n",
      "         [[ 0.1858]],\n",
      "\n",
      "         [[-0.0443]],\n",
      "\n",
      "         [[-0.0376]],\n",
      "\n",
      "         [[-0.6520]],\n",
      "\n",
      "         [[ 0.1335]],\n",
      "\n",
      "         [[-0.2976]],\n",
      "\n",
      "         [[-0.1453]],\n",
      "\n",
      "         [[ 0.3067]],\n",
      "\n",
      "         [[ 0.2486]],\n",
      "\n",
      "         [[-0.3699]],\n",
      "\n",
      "         [[-0.1378]],\n",
      "\n",
      "         [[-0.2812]],\n",
      "\n",
      "         [[-0.0880]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3077]],\n",
      "\n",
      "         [[ 0.0834]],\n",
      "\n",
      "         [[ 0.7448]],\n",
      "\n",
      "         [[ 0.0662]],\n",
      "\n",
      "         [[-0.5527]],\n",
      "\n",
      "         [[-0.3777]],\n",
      "\n",
      "         [[ 0.2077]],\n",
      "\n",
      "         [[ 0.2356]],\n",
      "\n",
      "         [[ 0.6937]],\n",
      "\n",
      "         [[-0.3305]],\n",
      "\n",
      "         [[-0.4042]],\n",
      "\n",
      "         [[-0.8490]],\n",
      "\n",
      "         [[ 0.1409]],\n",
      "\n",
      "         [[-0.1562]],\n",
      "\n",
      "         [[-0.1822]],\n",
      "\n",
      "         [[-0.1161]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1369]],\n",
      "\n",
      "         [[ 0.2333]],\n",
      "\n",
      "         [[ 0.0692]],\n",
      "\n",
      "         [[ 0.1205]],\n",
      "\n",
      "         [[ 0.1469]],\n",
      "\n",
      "         [[ 0.2614]],\n",
      "\n",
      "         [[-0.3492]],\n",
      "\n",
      "         [[-0.6026]],\n",
      "\n",
      "         [[ 0.6192]],\n",
      "\n",
      "         [[-0.2794]],\n",
      "\n",
      "         [[ 0.2965]],\n",
      "\n",
      "         [[ 0.2890]],\n",
      "\n",
      "         [[-0.1622]],\n",
      "\n",
      "         [[-0.0399]],\n",
      "\n",
      "         [[ 0.2497]],\n",
      "\n",
      "         [[-0.1337]]],\n",
      "\n",
      "\n",
      "        [[[-0.2220]],\n",
      "\n",
      "         [[ 0.5215]],\n",
      "\n",
      "         [[ 0.1413]],\n",
      "\n",
      "         [[ 0.2320]],\n",
      "\n",
      "         [[ 0.2285]],\n",
      "\n",
      "         [[ 0.3815]],\n",
      "\n",
      "         [[-0.3363]],\n",
      "\n",
      "         [[-0.5450]],\n",
      "\n",
      "         [[ 0.9556]],\n",
      "\n",
      "         [[ 0.1734]],\n",
      "\n",
      "         [[-0.0058]],\n",
      "\n",
      "         [[ 0.3356]],\n",
      "\n",
      "         [[ 0.2251]],\n",
      "\n",
      "         [[-0.1539]],\n",
      "\n",
      "         [[ 0.2900]],\n",
      "\n",
      "         [[ 0.0739]]],\n",
      "\n",
      "\n",
      "        [[[-0.4644]],\n",
      "\n",
      "         [[ 0.4541]],\n",
      "\n",
      "         [[-0.8302]],\n",
      "\n",
      "         [[-0.0533]],\n",
      "\n",
      "         [[ 0.3611]],\n",
      "\n",
      "         [[ 0.6502]],\n",
      "\n",
      "         [[-0.1368]],\n",
      "\n",
      "         [[ 0.4013]],\n",
      "\n",
      "         [[-0.2377]],\n",
      "\n",
      "         [[ 0.1848]],\n",
      "\n",
      "         [[ 0.2721]],\n",
      "\n",
      "         [[-0.6472]],\n",
      "\n",
      "         [[-0.2053]],\n",
      "\n",
      "         [[-0.4285]],\n",
      "\n",
      "         [[ 0.2342]],\n",
      "\n",
      "         [[-0.0742]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0607]],\n",
      "\n",
      "         [[ 0.3010]],\n",
      "\n",
      "         [[ 0.3417]],\n",
      "\n",
      "         [[ 0.4217]],\n",
      "\n",
      "         [[ 0.3091]],\n",
      "\n",
      "         [[ 0.2356]],\n",
      "\n",
      "         [[-0.1196]],\n",
      "\n",
      "         [[ 0.5443]],\n",
      "\n",
      "         [[-0.0455]],\n",
      "\n",
      "         [[-0.4124]],\n",
      "\n",
      "         [[-0.1648]],\n",
      "\n",
      "         [[ 0.0279]],\n",
      "\n",
      "         [[ 0.1535]],\n",
      "\n",
      "         [[-0.1089]],\n",
      "\n",
      "         [[ 0.4925]],\n",
      "\n",
      "         [[ 0.5899]]],\n",
      "\n",
      "\n",
      "        [[[-0.4563]],\n",
      "\n",
      "         [[ 0.0251]],\n",
      "\n",
      "         [[-0.3554]],\n",
      "\n",
      "         [[ 0.4476]],\n",
      "\n",
      "         [[ 0.2987]],\n",
      "\n",
      "         [[-0.3922]],\n",
      "\n",
      "         [[ 0.1568]],\n",
      "\n",
      "         [[-0.8798]],\n",
      "\n",
      "         [[-0.2921]],\n",
      "\n",
      "         [[-0.1458]],\n",
      "\n",
      "         [[ 0.1510]],\n",
      "\n",
      "         [[ 0.0631]],\n",
      "\n",
      "         [[-0.6300]],\n",
      "\n",
      "         [[-0.7153]],\n",
      "\n",
      "         [[-0.1564]],\n",
      "\n",
      "         [[ 0.0626]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4522]],\n",
      "\n",
      "         [[ 0.1055]],\n",
      "\n",
      "         [[ 0.0159]],\n",
      "\n",
      "         [[ 0.0960]],\n",
      "\n",
      "         [[-0.0819]],\n",
      "\n",
      "         [[-0.4635]],\n",
      "\n",
      "         [[ 0.5773]],\n",
      "\n",
      "         [[-0.3711]],\n",
      "\n",
      "         [[ 0.2194]],\n",
      "\n",
      "         [[-0.2567]],\n",
      "\n",
      "         [[-0.7455]],\n",
      "\n",
      "         [[ 0.4992]],\n",
      "\n",
      "         [[ 0.2067]],\n",
      "\n",
      "         [[-0.2702]],\n",
      "\n",
      "         [[-0.5544]],\n",
      "\n",
      "         [[-0.4568]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0551]],\n",
      "\n",
      "         [[-0.0685]],\n",
      "\n",
      "         [[ 0.0198]],\n",
      "\n",
      "         [[ 0.7350]],\n",
      "\n",
      "         [[-0.0783]],\n",
      "\n",
      "         [[ 0.1253]],\n",
      "\n",
      "         [[ 0.1762]],\n",
      "\n",
      "         [[-0.0590]],\n",
      "\n",
      "         [[-0.0464]],\n",
      "\n",
      "         [[-0.2669]],\n",
      "\n",
      "         [[ 0.3580]],\n",
      "\n",
      "         [[-0.3095]],\n",
      "\n",
      "         [[-0.2598]],\n",
      "\n",
      "         [[ 0.2527]],\n",
      "\n",
      "         [[ 0.3321]],\n",
      "\n",
      "         [[ 0.1693]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4214]],\n",
      "\n",
      "         [[-0.4161]],\n",
      "\n",
      "         [[ 0.4162]],\n",
      "\n",
      "         [[ 0.1232]],\n",
      "\n",
      "         [[ 0.5844]],\n",
      "\n",
      "         [[-0.2040]],\n",
      "\n",
      "         [[-0.5206]],\n",
      "\n",
      "         [[ 0.2796]],\n",
      "\n",
      "         [[-0.1119]],\n",
      "\n",
      "         [[ 0.4689]],\n",
      "\n",
      "         [[ 0.1962]],\n",
      "\n",
      "         [[ 0.0990]],\n",
      "\n",
      "         [[-0.1104]],\n",
      "\n",
      "         [[ 0.5327]],\n",
      "\n",
      "         [[-0.3670]],\n",
      "\n",
      "         [[-0.1044]]],\n",
      "\n",
      "\n",
      "        [[[-0.6558]],\n",
      "\n",
      "         [[ 0.2826]],\n",
      "\n",
      "         [[ 0.0568]],\n",
      "\n",
      "         [[ 1.0481]],\n",
      "\n",
      "         [[-0.3995]],\n",
      "\n",
      "         [[ 0.0482]],\n",
      "\n",
      "         [[ 0.4495]],\n",
      "\n",
      "         [[-0.7627]],\n",
      "\n",
      "         [[ 0.0129]],\n",
      "\n",
      "         [[ 0.9403]],\n",
      "\n",
      "         [[ 0.3019]],\n",
      "\n",
      "         [[ 0.5188]],\n",
      "\n",
      "         [[ 0.2360]],\n",
      "\n",
      "         [[ 0.0174]],\n",
      "\n",
      "         [[ 0.2719]],\n",
      "\n",
      "         [[-0.2577]]],\n",
      "\n",
      "\n",
      "        [[[ 0.5034]],\n",
      "\n",
      "         [[-0.0649]],\n",
      "\n",
      "         [[ 0.7161]],\n",
      "\n",
      "         [[-0.3092]],\n",
      "\n",
      "         [[ 0.6683]],\n",
      "\n",
      "         [[ 0.5035]],\n",
      "\n",
      "         [[-0.4142]],\n",
      "\n",
      "         [[ 0.2822]],\n",
      "\n",
      "         [[ 0.1923]],\n",
      "\n",
      "         [[ 0.1602]],\n",
      "\n",
      "         [[ 0.1735]],\n",
      "\n",
      "         [[ 0.0141]],\n",
      "\n",
      "         [[ 0.0585]],\n",
      "\n",
      "         [[ 0.1461]],\n",
      "\n",
      "         [[-0.3681]],\n",
      "\n",
      "         [[ 0.2523]]],\n",
      "\n",
      "\n",
      "        [[[-0.1890]],\n",
      "\n",
      "         [[-0.0988]],\n",
      "\n",
      "         [[ 0.0095]],\n",
      "\n",
      "         [[ 0.4999]],\n",
      "\n",
      "         [[ 0.0390]],\n",
      "\n",
      "         [[ 0.1262]],\n",
      "\n",
      "         [[-0.2241]],\n",
      "\n",
      "         [[-0.4362]],\n",
      "\n",
      "         [[-0.3235]],\n",
      "\n",
      "         [[-0.2451]],\n",
      "\n",
      "         [[-0.0079]],\n",
      "\n",
      "         [[-0.0143]],\n",
      "\n",
      "         [[ 0.4109]],\n",
      "\n",
      "         [[-0.4702]],\n",
      "\n",
      "         [[ 0.2156]],\n",
      "\n",
      "         [[ 0.1360]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2909]],\n",
      "\n",
      "         [[-0.3055]],\n",
      "\n",
      "         [[-0.6132]],\n",
      "\n",
      "         [[ 0.2253]],\n",
      "\n",
      "         [[ 0.1758]],\n",
      "\n",
      "         [[-0.0311]],\n",
      "\n",
      "         [[ 0.1415]],\n",
      "\n",
      "         [[-0.7126]],\n",
      "\n",
      "         [[-0.1747]],\n",
      "\n",
      "         [[ 0.4137]],\n",
      "\n",
      "         [[-0.1353]],\n",
      "\n",
      "         [[-0.8640]],\n",
      "\n",
      "         [[-0.3424]],\n",
      "\n",
      "         [[ 0.3187]],\n",
      "\n",
      "         [[-0.4092]],\n",
      "\n",
      "         [[ 0.3963]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0079]],\n",
      "\n",
      "         [[ 0.3515]],\n",
      "\n",
      "         [[-0.2464]],\n",
      "\n",
      "         [[-0.3280]],\n",
      "\n",
      "         [[-0.0802]],\n",
      "\n",
      "         [[-0.5051]],\n",
      "\n",
      "         [[ 0.3394]],\n",
      "\n",
      "         [[-0.6738]],\n",
      "\n",
      "         [[-0.3411]],\n",
      "\n",
      "         [[-0.4263]],\n",
      "\n",
      "         [[-0.6725]],\n",
      "\n",
      "         [[ 0.7512]],\n",
      "\n",
      "         [[-0.1258]],\n",
      "\n",
      "         [[-0.2327]],\n",
      "\n",
      "         [[-0.1691]],\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         [[ 0.5854]]]], requires_grad=True))\n",
      "('features.1.conv.1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.1.conv.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.1.conv.3.weight', Parameter containing:\n",
      "tensor([[[[ 0.0220, -0.0119,  0.0645],\n",
      "          [-0.2035,  0.0130, -0.1746],\n",
      "          [-0.0232,  0.1081,  0.0560]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0080, -0.1044, -0.0655],\n",
      "          [ 0.0424,  0.3476,  0.0542],\n",
      "          [-0.0065, -0.0147,  0.0434]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0475,  0.1159,  0.0671],\n",
      "          [-0.0005, -0.2071, -0.1955],\n",
      "          [ 0.1043,  0.1108,  0.0814]]],\n",
      "\n",
      "\n",
      "        [[[-0.1778, -0.0558,  0.0613],\n",
      "          [ 0.1198, -0.0083,  0.1221],\n",
      "          [-0.1138, -0.0839, -0.0791]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0892, -0.1596, -0.0854],\n",
      "          [-0.0654, -0.1480,  0.1997],\n",
      "          [-0.0615,  0.0774,  0.0369]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0742,  0.0389,  0.0145],\n",
      "          [ 0.0318,  0.0384,  0.1893],\n",
      "          [ 0.0661, -0.0101, -0.1041]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0373, -0.0775, -0.0339],\n",
      "          [-0.1803, -0.0675, -0.0542],\n",
      "          [ 0.1395, -0.0610,  0.1679]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2401, -0.0082, -0.0581],\n",
      "          [ 0.2446,  0.3776, -0.1576],\n",
      "          [ 0.0482,  0.0954,  0.0690]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0297, -0.1353, -0.1912],\n",
      "          [ 0.2588,  0.1491, -0.0424],\n",
      "          [ 0.0742,  0.1700, -0.1582]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1196,  0.0237, -0.0760],\n",
      "          [-0.0769,  0.0858, -0.1869],\n",
      "          [-0.1356, -0.0860, -0.0540]]],\n",
      "\n",
      "\n",
      "        [[[-0.0742, -0.2281, -0.0254],\n",
      "          [-0.2344, -0.1038, -0.1427],\n",
      "          [ 0.0334, -0.1091, -0.0132]]],\n",
      "\n",
      "\n",
      "        [[[-0.0395,  0.1281, -0.1063],\n",
      "          [ 0.2865,  0.1933,  0.1740],\n",
      "          [-0.0212, -0.2096, -0.1254]]],\n",
      "\n",
      "\n",
      "        [[[-0.0260,  0.2045,  0.0200],\n",
      "          [ 0.1142, -0.0752, -0.0868],\n",
      "          [ 0.0935, -0.0853, -0.2137]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0076,  0.0464,  0.1187],\n",
      "          [ 0.0296, -0.0599, -0.3575],\n",
      "          [ 0.2113, -0.0500,  0.2673]]],\n",
      "\n",
      "\n",
      "        [[[-0.0366, -0.1785,  0.0459],\n",
      "          [-0.0991, -0.0403, -0.0719],\n",
      "          [-0.1077, -0.1041, -0.1019]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2192,  0.0826,  0.0874],\n",
      "          [ 0.0823, -0.0263, -0.2042],\n",
      "          [ 0.0250, -0.0483,  0.2376]]]], requires_grad=True))\n",
      "('features.1.conv.4.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.1.conv.4.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.1.conv.5.fc.0.weight', Parameter containing:\n",
      "tensor([[ 1.1252e-02, -9.6680e-03, -3.7564e-04,  7.6733e-05, -9.1492e-03,\n",
      "          2.6132e-02,  7.2101e-03, -6.8572e-03, -1.9226e-02,  7.2019e-03,\n",
      "         -8.7541e-03, -1.0097e-02,  1.2819e-04,  3.0073e-04, -9.4741e-04,\n",
      "          3.9591e-03],\n",
      "        [-3.8793e-03,  7.4205e-03, -9.4281e-03, -2.7720e-03,  3.0687e-03,\n",
      "          1.1981e-02,  4.2008e-03,  7.5799e-03,  1.3370e-03, -5.8202e-03,\n",
      "         -5.5763e-03, -1.4308e-02,  1.3173e-02,  2.9634e-03, -9.6727e-03,\n",
      "          5.6927e-03],\n",
      "        [-5.4456e-03,  2.6982e-02,  2.0031e-03, -4.5192e-03, -1.2507e-02,\n",
      "         -2.9597e-02, -2.1426e-03,  2.6485e-03, -1.1306e-02, -2.0815e-03,\n",
      "          4.2566e-03,  2.6191e-03, -1.6918e-02,  5.1444e-03,  1.1885e-02,\n",
      "          9.2940e-03],\n",
      "        [ 6.1901e-04, -9.9556e-03, -4.8385e-03, -1.0761e-02,  4.7190e-03,\n",
      "          5.3892e-03, -8.3990e-03,  5.2791e-03,  1.1739e-02,  2.3796e-02,\n",
      "         -1.2605e-03,  4.1224e-03, -2.5691e-02, -7.7751e-03,  8.0182e-03,\n",
      "         -1.7105e-02]], requires_grad=True))\n",
      "('features.1.conv.5.fc.2.weight', Parameter containing:\n",
      "tensor([[-0.0059, -0.0046, -0.0099, -0.0121],\n",
      "        [-0.0006, -0.0022,  0.0095, -0.0133],\n",
      "        [-0.0053,  0.0111,  0.0145, -0.0088],\n",
      "        [ 0.0086,  0.0064,  0.0017, -0.0042],\n",
      "        [-0.0035, -0.0155, -0.0253,  0.0002],\n",
      "        [ 0.0029, -0.0209, -0.0073,  0.0124],\n",
      "        [-0.0096, -0.0094,  0.0080, -0.0132],\n",
      "        [ 0.0075,  0.0032,  0.0047,  0.0179],\n",
      "        [ 0.0051,  0.0061,  0.0034,  0.0193],\n",
      "        [ 0.0081, -0.0054, -0.0191, -0.0007],\n",
      "        [-0.0034,  0.0048,  0.0159, -0.0151],\n",
      "        [-0.0030,  0.0008,  0.0053, -0.0186],\n",
      "        [ 0.0067, -0.0008, -0.0138,  0.0055],\n",
      "        [ 0.0134,  0.0145,  0.0018,  0.0112],\n",
      "        [ 0.0026, -0.0164, -0.0053, -0.0030],\n",
      "        [-0.0087, -0.0143,  0.0091,  0.0144]], requires_grad=True))\n",
      "('features.1.conv.7.weight', Parameter containing:\n",
      "tensor([[[[-0.4311]],\n",
      "\n",
      "         [[ 0.0197]],\n",
      "\n",
      "         [[ 0.2310]],\n",
      "\n",
      "         [[ 0.3854]],\n",
      "\n",
      "         [[-0.0676]],\n",
      "\n",
      "         [[-0.2881]],\n",
      "\n",
      "         [[-0.1321]],\n",
      "\n",
      "         [[ 0.3246]],\n",
      "\n",
      "         [[-0.0910]],\n",
      "\n",
      "         [[-0.3730]],\n",
      "\n",
      "         [[-0.1111]],\n",
      "\n",
      "         [[-0.2016]],\n",
      "\n",
      "         [[-0.5581]],\n",
      "\n",
      "         [[-0.2207]],\n",
      "\n",
      "         [[-0.0846]],\n",
      "\n",
      "         [[ 0.1145]]],\n",
      "\n",
      "\n",
      "        [[[-0.3926]],\n",
      "\n",
      "         [[-0.4841]],\n",
      "\n",
      "         [[ 0.2026]],\n",
      "\n",
      "         [[ 0.4839]],\n",
      "\n",
      "         [[ 0.4900]],\n",
      "\n",
      "         [[ 0.1692]],\n",
      "\n",
      "         [[-0.8302]],\n",
      "\n",
      "         [[ 0.0067]],\n",
      "\n",
      "         [[ 0.1294]],\n",
      "\n",
      "         [[-0.7739]],\n",
      "\n",
      "         [[-0.4081]],\n",
      "\n",
      "         [[ 0.4516]],\n",
      "\n",
      "         [[ 0.0787]],\n",
      "\n",
      "         [[ 0.3469]],\n",
      "\n",
      "         [[ 0.1726]],\n",
      "\n",
      "         [[-0.6646]]],\n",
      "\n",
      "\n",
      "        [[[-0.0019]],\n",
      "\n",
      "         [[-0.3415]],\n",
      "\n",
      "         [[-0.1210]],\n",
      "\n",
      "         [[ 0.0105]],\n",
      "\n",
      "         [[ 0.3037]],\n",
      "\n",
      "         [[-0.2762]],\n",
      "\n",
      "         [[ 0.0903]],\n",
      "\n",
      "         [[-0.3558]],\n",
      "\n",
      "         [[ 0.3423]],\n",
      "\n",
      "         [[ 0.7130]],\n",
      "\n",
      "         [[ 0.0542]],\n",
      "\n",
      "         [[ 0.0548]],\n",
      "\n",
      "         [[ 0.4645]],\n",
      "\n",
      "         [[ 0.6064]],\n",
      "\n",
      "         [[-0.4462]],\n",
      "\n",
      "         [[ 0.3260]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2816]],\n",
      "\n",
      "         [[-0.0966]],\n",
      "\n",
      "         [[ 0.2593]],\n",
      "\n",
      "         [[ 0.1048]],\n",
      "\n",
      "         [[ 0.1353]],\n",
      "\n",
      "         [[ 0.2675]],\n",
      "\n",
      "         [[ 0.4512]],\n",
      "\n",
      "         [[ 0.4258]],\n",
      "\n",
      "         [[ 0.1506]],\n",
      "\n",
      "         [[-0.3191]],\n",
      "\n",
      "         [[-0.0729]],\n",
      "\n",
      "         [[-0.2493]],\n",
      "\n",
      "         [[ 0.1517]],\n",
      "\n",
      "         [[-0.0110]],\n",
      "\n",
      "         [[ 0.0393]],\n",
      "\n",
      "         [[ 0.5081]]],\n",
      "\n",
      "\n",
      "        [[[-0.3225]],\n",
      "\n",
      "         [[ 0.0769]],\n",
      "\n",
      "         [[-0.2444]],\n",
      "\n",
      "         [[ 0.3079]],\n",
      "\n",
      "         [[ 0.2970]],\n",
      "\n",
      "         [[ 0.2333]],\n",
      "\n",
      "         [[ 0.3605]],\n",
      "\n",
      "         [[ 0.2907]],\n",
      "\n",
      "         [[ 0.4590]],\n",
      "\n",
      "         [[-0.0034]],\n",
      "\n",
      "         [[-0.0035]],\n",
      "\n",
      "         [[ 0.2131]],\n",
      "\n",
      "         [[-0.0577]],\n",
      "\n",
      "         [[ 0.0866]],\n",
      "\n",
      "         [[-0.2505]],\n",
      "\n",
      "         [[ 0.1113]]],\n",
      "\n",
      "\n",
      "        [[[-0.3246]],\n",
      "\n",
      "         [[ 0.2536]],\n",
      "\n",
      "         [[-0.3580]],\n",
      "\n",
      "         [[ 0.1030]],\n",
      "\n",
      "         [[ 0.1297]],\n",
      "\n",
      "         [[ 0.3625]],\n",
      "\n",
      "         [[ 0.1731]],\n",
      "\n",
      "         [[-0.6614]],\n",
      "\n",
      "         [[ 0.0203]],\n",
      "\n",
      "         [[-0.2221]],\n",
      "\n",
      "         [[-0.3967]],\n",
      "\n",
      "         [[ 0.9827]],\n",
      "\n",
      "         [[-0.5588]],\n",
      "\n",
      "         [[-0.3210]],\n",
      "\n",
      "         [[-0.1961]],\n",
      "\n",
      "         [[ 0.6346]]],\n",
      "\n",
      "\n",
      "        [[[-0.4639]],\n",
      "\n",
      "         [[-0.6007]],\n",
      "\n",
      "         [[-0.0868]],\n",
      "\n",
      "         [[-0.4027]],\n",
      "\n",
      "         [[ 0.0823]],\n",
      "\n",
      "         [[-0.1342]],\n",
      "\n",
      "         [[ 0.6005]],\n",
      "\n",
      "         [[-0.0440]],\n",
      "\n",
      "         [[-0.1644]],\n",
      "\n",
      "         [[-0.0095]],\n",
      "\n",
      "         [[ 0.1012]],\n",
      "\n",
      "         [[-0.0115]],\n",
      "\n",
      "         [[-0.6253]],\n",
      "\n",
      "         [[-0.1273]],\n",
      "\n",
      "         [[-0.1926]],\n",
      "\n",
      "         [[ 0.4449]]],\n",
      "\n",
      "\n",
      "        [[[-0.7243]],\n",
      "\n",
      "         [[ 0.2236]],\n",
      "\n",
      "         [[ 0.0989]],\n",
      "\n",
      "         [[-0.3955]],\n",
      "\n",
      "         [[-0.4179]],\n",
      "\n",
      "         [[ 0.6092]],\n",
      "\n",
      "         [[-0.2835]],\n",
      "\n",
      "         [[ 0.1838]],\n",
      "\n",
      "         [[ 0.7022]],\n",
      "\n",
      "         [[-0.2071]],\n",
      "\n",
      "         [[ 0.6864]],\n",
      "\n",
      "         [[-0.1487]],\n",
      "\n",
      "         [[ 0.5740]],\n",
      "\n",
      "         [[-0.2125]],\n",
      "\n",
      "         [[-0.6642]],\n",
      "\n",
      "         [[-0.2763]]],\n",
      "\n",
      "\n",
      "        [[[-0.2715]],\n",
      "\n",
      "         [[-0.1549]],\n",
      "\n",
      "         [[-0.1344]],\n",
      "\n",
      "         [[-0.2782]],\n",
      "\n",
      "         [[ 0.0326]],\n",
      "\n",
      "         [[-0.2100]],\n",
      "\n",
      "         [[ 0.3799]],\n",
      "\n",
      "         [[-0.3549]],\n",
      "\n",
      "         [[-0.0458]],\n",
      "\n",
      "         [[-0.4766]],\n",
      "\n",
      "         [[ 0.3801]],\n",
      "\n",
      "         [[-0.4214]],\n",
      "\n",
      "         [[-0.2868]],\n",
      "\n",
      "         [[ 0.5852]],\n",
      "\n",
      "         [[ 0.1245]],\n",
      "\n",
      "         [[ 0.1560]]],\n",
      "\n",
      "\n",
      "        [[[-0.1917]],\n",
      "\n",
      "         [[-0.5651]],\n",
      "\n",
      "         [[-0.3387]],\n",
      "\n",
      "         [[ 0.5228]],\n",
      "\n",
      "         [[ 0.0409]],\n",
      "\n",
      "         [[ 0.2954]],\n",
      "\n",
      "         [[-0.4541]],\n",
      "\n",
      "         [[ 0.0277]],\n",
      "\n",
      "         [[ 0.1967]],\n",
      "\n",
      "         [[ 0.1036]],\n",
      "\n",
      "         [[ 0.4478]],\n",
      "\n",
      "         [[-0.2823]],\n",
      "\n",
      "         [[-0.1892]],\n",
      "\n",
      "         [[ 0.0625]],\n",
      "\n",
      "         [[-0.1053]],\n",
      "\n",
      "         [[ 0.4040]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2243]],\n",
      "\n",
      "         [[ 0.3148]],\n",
      "\n",
      "         [[-0.0283]],\n",
      "\n",
      "         [[ 0.0983]],\n",
      "\n",
      "         [[-0.1564]],\n",
      "\n",
      "         [[-0.1285]],\n",
      "\n",
      "         [[-0.4300]],\n",
      "\n",
      "         [[ 0.0190]],\n",
      "\n",
      "         [[-0.5224]],\n",
      "\n",
      "         [[-0.1597]],\n",
      "\n",
      "         [[ 0.1815]],\n",
      "\n",
      "         [[-0.5134]],\n",
      "\n",
      "         [[ 0.2237]],\n",
      "\n",
      "         [[-0.0352]],\n",
      "\n",
      "         [[ 0.3089]],\n",
      "\n",
      "         [[ 0.6722]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1135]],\n",
      "\n",
      "         [[ 0.0416]],\n",
      "\n",
      "         [[-0.1250]],\n",
      "\n",
      "         [[ 0.5620]],\n",
      "\n",
      "         [[-0.1273]],\n",
      "\n",
      "         [[ 0.4670]],\n",
      "\n",
      "         [[-0.1842]],\n",
      "\n",
      "         [[ 0.4872]],\n",
      "\n",
      "         [[ 0.2390]],\n",
      "\n",
      "         [[-0.2892]],\n",
      "\n",
      "         [[ 0.3299]],\n",
      "\n",
      "         [[ 0.2761]],\n",
      "\n",
      "         [[ 0.1445]],\n",
      "\n",
      "         [[ 0.6486]],\n",
      "\n",
      "         [[ 0.3732]],\n",
      "\n",
      "         [[-0.4109]]],\n",
      "\n",
      "\n",
      "        [[[-0.1890]],\n",
      "\n",
      "         [[ 0.4869]],\n",
      "\n",
      "         [[ 0.2648]],\n",
      "\n",
      "         [[-0.2064]],\n",
      "\n",
      "         [[-0.1280]],\n",
      "\n",
      "         [[ 0.7710]],\n",
      "\n",
      "         [[-0.2429]],\n",
      "\n",
      "         [[ 0.3003]],\n",
      "\n",
      "         [[-0.5354]],\n",
      "\n",
      "         [[-1.0654]],\n",
      "\n",
      "         [[-0.0911]],\n",
      "\n",
      "         [[-0.1930]],\n",
      "\n",
      "         [[-0.3421]],\n",
      "\n",
      "         [[-0.0828]],\n",
      "\n",
      "         [[ 0.4236]],\n",
      "\n",
      "         [[ 0.3009]]],\n",
      "\n",
      "\n",
      "        [[[-0.1459]],\n",
      "\n",
      "         [[ 0.1451]],\n",
      "\n",
      "         [[-0.1842]],\n",
      "\n",
      "         [[ 0.2925]],\n",
      "\n",
      "         [[ 0.1759]],\n",
      "\n",
      "         [[-0.1735]],\n",
      "\n",
      "         [[-0.3814]],\n",
      "\n",
      "         [[ 0.5556]],\n",
      "\n",
      "         [[ 0.1128]],\n",
      "\n",
      "         [[-0.0339]],\n",
      "\n",
      "         [[ 0.1497]],\n",
      "\n",
      "         [[ 0.3575]],\n",
      "\n",
      "         [[ 0.3102]],\n",
      "\n",
      "         [[ 0.2736]],\n",
      "\n",
      "         [[ 0.3154]],\n",
      "\n",
      "         [[ 0.3435]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1464]],\n",
      "\n",
      "         [[-0.5203]],\n",
      "\n",
      "         [[ 0.1434]],\n",
      "\n",
      "         [[ 0.7247]],\n",
      "\n",
      "         [[-0.0619]],\n",
      "\n",
      "         [[-0.4660]],\n",
      "\n",
      "         [[ 0.3584]],\n",
      "\n",
      "         [[ 0.3672]],\n",
      "\n",
      "         [[ 0.0069]],\n",
      "\n",
      "         [[ 0.3366]],\n",
      "\n",
      "         [[-0.1290]],\n",
      "\n",
      "         [[-0.3939]],\n",
      "\n",
      "         [[ 0.4267]],\n",
      "\n",
      "         [[ 0.4582]],\n",
      "\n",
      "         [[ 0.2488]],\n",
      "\n",
      "         [[ 0.4658]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3630]],\n",
      "\n",
      "         [[ 0.0393]],\n",
      "\n",
      "         [[-0.0963]],\n",
      "\n",
      "         [[ 0.1093]],\n",
      "\n",
      "         [[ 0.1444]],\n",
      "\n",
      "         [[-0.4208]],\n",
      "\n",
      "         [[-0.2529]],\n",
      "\n",
      "         [[-0.1834]],\n",
      "\n",
      "         [[ 0.0418]],\n",
      "\n",
      "         [[-0.0606]],\n",
      "\n",
      "         [[-0.6313]],\n",
      "\n",
      "         [[ 0.2585]],\n",
      "\n",
      "         [[-0.2771]],\n",
      "\n",
      "         [[ 0.2524]],\n",
      "\n",
      "         [[-0.1895]],\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         [[ 0.5893]]]], requires_grad=True))\n",
      "('features.1.conv.8.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.1.conv.8.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.2.conv.0.weight', Parameter containing:\n",
      "tensor([[[[ 0.0878]],\n",
      "\n",
      "         [[ 0.0755]],\n",
      "\n",
      "         [[-0.1898]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0092]],\n",
      "\n",
      "         [[-0.1700]],\n",
      "\n",
      "         [[-0.1280]]],\n",
      "\n",
      "\n",
      "        [[[-0.2796]],\n",
      "\n",
      "         [[-0.0240]],\n",
      "\n",
      "         [[-0.0534]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2015]],\n",
      "\n",
      "         [[ 0.1329]],\n",
      "\n",
      "         [[ 0.1055]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1362]],\n",
      "\n",
      "         [[-0.3431]],\n",
      "\n",
      "         [[ 0.1590]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0062]],\n",
      "\n",
      "         [[ 0.1908]],\n",
      "\n",
      "         [[ 0.1408]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1079]],\n",
      "\n",
      "         [[-0.3540]],\n",
      "\n",
      "         [[ 0.1129]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0574]],\n",
      "\n",
      "         [[-0.2639]],\n",
      "\n",
      "         [[ 0.0420]]],\n",
      "\n",
      "\n",
      "        [[[-0.0689]],\n",
      "\n",
      "         [[ 0.0329]],\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0768]],\n",
      "\n",
      "         [[ 0.0728]],\n",
      "\n",
      "         [[ 0.0625]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0063]],\n",
      "\n",
      "         [[ 0.1120]],\n",
      "\n",
      "         [[ 0.2072]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1501]],\n",
      "\n",
      "         [[-0.0897]],\n",
      "\n",
      "         [[-0.0084]]]], requires_grad=True))\n",
      "('features.2.conv.1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.2.conv.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.2.conv.3.weight', Parameter containing:\n",
      "tensor([[[[ 1.0832e-02, -3.8379e-02,  5.2510e-02],\n",
      "          [ 4.7911e-02,  3.2456e-02,  9.2247e-02],\n",
      "          [-1.6602e-02,  6.9904e-02, -3.9634e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0782e-01,  3.0812e-02, -4.4718e-02],\n",
      "          [-4.8169e-02, -1.3087e-02,  5.3979e-02],\n",
      "          [-1.7808e-02, -7.6117e-02,  4.8453e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9707e-02,  4.8762e-02,  1.0600e-02],\n",
      "          [ 6.2263e-02, -6.3150e-02,  2.6697e-02],\n",
      "          [ 3.5272e-02, -1.7541e-02, -2.5007e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.7047e-02, -2.5309e-02, -4.0667e-02],\n",
      "          [ 4.0517e-02,  1.2933e-02,  5.2037e-02],\n",
      "          [ 5.2818e-03,  3.0882e-03,  1.1086e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1052e-02,  2.3372e-02,  9.8336e-02],\n",
      "          [-1.1206e-02,  9.6538e-03,  7.6413e-02],\n",
      "          [-4.0448e-02,  7.7140e-02, -6.1308e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.4004e-02, -1.3777e-02,  8.5254e-02],\n",
      "          [ 2.7151e-02, -5.1505e-02,  2.3225e-02],\n",
      "          [ 4.9454e-02, -1.2329e-02,  7.6579e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0119e-02, -8.8670e-02, -2.1778e-03],\n",
      "          [ 3.1666e-02,  8.1870e-02,  5.3591e-02],\n",
      "          [-9.5598e-02,  8.1461e-02, -3.7744e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7389e-03,  1.1611e-01, -2.8201e-02],\n",
      "          [-2.9607e-02,  2.8650e-04,  1.4577e-02],\n",
      "          [-3.9242e-02,  1.2834e-01,  2.7695e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0295e-02,  7.8920e-02,  4.2898e-02],\n",
      "          [ 4.4386e-02,  1.4522e-02,  4.6435e-02],\n",
      "          [ 3.4036e-02,  6.8438e-03, -9.5887e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4002e-02,  1.9081e-02,  1.3023e-01],\n",
      "          [ 1.7868e-02,  6.1679e-02, -7.1209e-02],\n",
      "          [-6.8884e-02, -3.6716e-02,  4.5352e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1745e-02, -1.9161e-02,  4.0141e-02],\n",
      "          [ 4.1024e-05, -2.1794e-02, -5.2852e-02],\n",
      "          [-6.3635e-03,  1.2726e-01, -1.2026e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0127e-02,  2.7877e-03,  2.5850e-02],\n",
      "          [ 1.4807e-02, -9.6681e-02,  3.7958e-02],\n",
      "          [-5.6906e-02,  3.1824e-02, -8.6300e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.3849e-02, -2.7092e-02, -4.2653e-02],\n",
      "          [ 4.7793e-02, -7.4426e-02, -1.6687e-02],\n",
      "          [ 2.6699e-02, -4.6906e-02, -2.8923e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7974e-02,  4.7051e-02,  2.1801e-02],\n",
      "          [ 1.9841e-02, -1.0490e-02,  5.2227e-02],\n",
      "          [ 1.5852e-03, -4.0731e-02, -3.9120e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2571e-02, -5.2081e-02, -3.2436e-02],\n",
      "          [ 3.2523e-02, -3.1291e-02, -1.0777e-01],\n",
      "          [-1.0077e-01, -9.9188e-02,  9.9406e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.3615e-02,  5.7368e-02,  5.6039e-02],\n",
      "          [ 6.6090e-02,  3.2280e-02, -1.2523e-01],\n",
      "          [ 1.0989e-01, -6.7659e-02, -4.3366e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6669e-02,  2.2717e-02, -8.6325e-03],\n",
      "          [-8.3900e-02,  3.3954e-02, -3.0610e-02],\n",
      "          [ 1.9354e-02,  5.7512e-02, -7.2152e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7087e-03,  9.2898e-02,  1.1521e-02],\n",
      "          [-1.1286e-02,  1.2687e-02,  9.9675e-02],\n",
      "          [-1.5347e-02, -4.9164e-02, -1.8870e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9439e-02, -7.6862e-03,  1.7662e-02],\n",
      "          [-1.1783e-02,  1.7986e-02,  2.6477e-02],\n",
      "          [ 4.7635e-02,  3.4829e-02, -2.5285e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6521e-02, -1.5932e-02, -2.8765e-02],\n",
      "          [-1.9717e-02, -1.1087e-01,  3.2325e-02],\n",
      "          [-2.0504e-02,  7.8462e-02,  7.7322e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5956e-03,  8.6599e-02, -7.4107e-02],\n",
      "          [ 1.6827e-02,  8.5328e-02,  1.2529e-01],\n",
      "          [-3.7135e-02, -9.7352e-02, -9.2852e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6160e-03, -1.8619e-02,  1.4724e-02],\n",
      "          [ 1.1798e-01,  6.2363e-02,  6.8355e-03],\n",
      "          [-7.1698e-02, -5.0992e-03, -3.5126e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.4716e-03,  8.5304e-02, -1.0423e-02],\n",
      "          [-4.2687e-02,  3.4792e-02,  1.2217e-02],\n",
      "          [-1.4406e-02,  1.8835e-02,  3.8849e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.2067e-02,  1.0405e-02, -2.8639e-02],\n",
      "          [-3.7584e-03,  3.9348e-02,  1.5751e-02],\n",
      "          [-3.3975e-02, -1.3072e-02,  3.1377e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2412e-02, -3.4561e-02, -2.1033e-02],\n",
      "          [-7.9317e-02,  1.7688e-02, -1.4776e-02],\n",
      "          [ 3.2363e-02, -2.5497e-02, -5.0199e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6853e-02,  1.8026e-01,  7.1539e-02],\n",
      "          [-5.7659e-02, -2.5121e-02, -4.8774e-03],\n",
      "          [-4.3408e-02, -1.1317e-01,  8.7651e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6551e-02,  2.0285e-02, -1.6724e-02],\n",
      "          [-1.2040e-01,  9.7742e-02,  4.4501e-02],\n",
      "          [-2.0039e-02, -1.8621e-02,  8.7348e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7169e-02,  5.6585e-02, -8.5330e-02],\n",
      "          [ 7.8850e-02,  3.6738e-02,  5.1679e-02],\n",
      "          [ 4.2738e-04, -5.3949e-02,  1.6681e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6234e-03,  1.0185e-01,  6.0747e-02],\n",
      "          [ 7.2508e-02,  3.2480e-02,  2.3188e-02],\n",
      "          [ 3.1034e-02, -1.3660e-03, -2.1064e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3861e-02,  6.2318e-02, -5.5172e-02],\n",
      "          [ 7.5263e-02,  2.7743e-02,  5.9348e-02],\n",
      "          [ 4.9020e-02, -6.1564e-02, -1.5793e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2175e-02, -6.1426e-02, -1.7725e-02],\n",
      "          [ 1.2347e-01,  1.3953e-02,  7.0931e-02],\n",
      "          [-4.3547e-02,  2.3866e-02,  2.9534e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.9456e-02,  1.0179e-01, -5.6135e-02],\n",
      "          [ 1.9714e-02,  6.9630e-02, -7.4910e-02],\n",
      "          [ 6.8785e-02,  5.6892e-02,  5.5364e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.8505e-02, -4.3250e-02,  4.4159e-02],\n",
      "          [ 1.2816e-02,  8.7492e-02,  8.0886e-02],\n",
      "          [-3.5538e-02,  8.8770e-02, -6.7478e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3679e-02, -5.6583e-02,  1.0997e-02],\n",
      "          [-6.1636e-02, -7.8864e-02, -8.1915e-02],\n",
      "          [-1.0788e-02, -6.5385e-02,  4.2842e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.4366e-02,  7.6970e-02,  3.6100e-02],\n",
      "          [ 5.2997e-02,  7.6964e-02,  1.2746e-02],\n",
      "          [ 5.4480e-03,  1.0974e-01, -5.5672e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.2498e-02,  1.0976e-02, -6.5751e-02],\n",
      "          [ 9.2466e-02, -9.4676e-02,  1.4773e-02],\n",
      "          [-1.5121e-02, -2.9263e-03, -1.6958e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5500e-02, -1.2635e-01,  4.6769e-02],\n",
      "          [-1.0233e-01,  6.7120e-03, -7.1950e-02],\n",
      "          [-7.4408e-02, -9.9210e-04, -1.3140e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.2787e-02,  8.3108e-02,  9.4067e-02],\n",
      "          [-2.5146e-02,  2.1101e-02, -4.8777e-03],\n",
      "          [ 4.8320e-02, -6.3836e-02, -5.5147e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2013e-02,  8.6599e-02, -1.0941e-01],\n",
      "          [-1.0815e-01,  4.4737e-02, -4.7418e-02],\n",
      "          [-1.5255e-03,  2.9530e-02, -1.2467e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6315e-02, -1.0313e-02, -2.2998e-02],\n",
      "          [ 5.0452e-02,  5.3411e-02, -4.8370e-04],\n",
      "          [ 2.0201e-03, -3.0257e-03, -5.8062e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0399e-02, -1.3375e-02,  6.0948e-02],\n",
      "          [ 7.2233e-02, -3.6128e-02,  7.2502e-02],\n",
      "          [-4.8138e-02,  2.9820e-02, -3.1887e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.9470e-02, -4.2796e-02,  5.8893e-02],\n",
      "          [ 6.2815e-02,  5.1652e-02,  2.4766e-02],\n",
      "          [ 7.7512e-02, -5.4022e-02, -4.7157e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0130e-02, -5.1117e-02,  2.1013e-02],\n",
      "          [-5.5916e-02,  4.3254e-02, -1.5985e-02],\n",
      "          [ 2.2921e-02, -9.1211e-02,  2.6583e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6001e-02, -4.6824e-02, -9.1827e-04],\n",
      "          [ 3.6441e-02, -1.8322e-03,  2.5875e-03],\n",
      "          [-7.6391e-02,  3.0871e-02, -2.1968e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.9509e-02, -7.9180e-02,  3.2732e-02],\n",
      "          [-2.2421e-02, -5.4140e-02,  4.7721e-02],\n",
      "          [-2.5726e-02, -2.8137e-02, -2.2829e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.2210e-02,  7.4805e-02, -3.0817e-02],\n",
      "          [ 1.0323e-01,  2.4978e-02,  7.5655e-02],\n",
      "          [ 6.6070e-03, -2.9382e-02,  7.4290e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.7714e-04,  7.6121e-02, -3.4750e-02],\n",
      "          [-9.7453e-02, -1.4857e-02,  1.9962e-02],\n",
      "          [ 6.2404e-02,  1.4551e-02, -1.3120e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.5995e-02,  5.3704e-03,  5.9760e-02],\n",
      "          [-3.4693e-02,  1.0218e-01,  1.6314e-02],\n",
      "          [ 8.3868e-03,  1.6842e-02, -7.2590e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.4531e-02,  2.1512e-02,  2.2113e-02],\n",
      "          [ 7.2119e-03,  3.3430e-02,  4.5650e-03],\n",
      "          [-1.2200e-02, -3.3649e-02,  3.1053e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.9597e-02, -4.3847e-03,  4.8942e-02],\n",
      "          [ 1.7218e-02, -1.1320e-01,  1.6523e-02],\n",
      "          [-1.5743e-02,  1.9641e-02,  3.5965e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.9006e-02,  3.8477e-03, -3.0137e-02],\n",
      "          [ 3.4099e-02, -3.6332e-03,  6.9323e-02],\n",
      "          [-1.3933e-02, -8.2284e-02,  7.0973e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0802e-02, -1.1183e-01, -6.9589e-02],\n",
      "          [-4.8701e-02,  3.0314e-02, -4.5344e-02],\n",
      "          [ 6.5458e-02,  2.5761e-02, -4.6947e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.5561e-02, -3.6218e-02, -7.5152e-02],\n",
      "          [-1.2853e-03,  6.9519e-02, -1.8797e-02],\n",
      "          [ 7.4214e-02, -2.0962e-02,  1.6817e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2699e-01,  1.1950e-01, -4.4551e-02],\n",
      "          [-5.2766e-02,  7.6490e-03, -2.9937e-02],\n",
      "          [ 2.5720e-02,  2.7019e-02,  3.6549e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6483e-02, -2.1858e-02, -2.6526e-02],\n",
      "          [ 7.0806e-02, -3.6859e-02,  1.0272e-02],\n",
      "          [ 2.3587e-02,  7.6581e-03,  5.7730e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0475e-02,  1.4127e-03, -3.4890e-02],\n",
      "          [ 4.7286e-02,  4.1289e-02,  4.9690e-02],\n",
      "          [-8.1993e-02,  3.9062e-02, -3.8679e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8928e-02,  1.4880e-02,  1.5573e-04],\n",
      "          [-7.0706e-03, -1.1790e-01, -4.0469e-02],\n",
      "          [-2.7789e-02, -3.5817e-02, -9.1711e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0315e-03,  1.5072e-02, -4.4612e-02],\n",
      "          [ 3.8000e-02,  6.7876e-03, -1.4787e-01],\n",
      "          [-4.7726e-03,  1.6059e-02,  4.0431e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1649e-02, -7.8414e-02,  1.1246e-02],\n",
      "          [ 4.3109e-03,  6.1418e-03, -4.8191e-02],\n",
      "          [ 4.9189e-02,  4.1973e-03, -3.7124e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2679e-02, -5.0636e-02, -2.2251e-02],\n",
      "          [-1.6032e-02,  3.4521e-02, -6.8529e-02],\n",
      "          [ 4.0306e-02,  7.5619e-02,  5.4062e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8269e-02, -1.3338e-02,  1.7189e-02],\n",
      "          [-9.9799e-03,  1.3236e-02, -6.0554e-02],\n",
      "          [-1.4835e-03,  1.0037e-02, -2.2375e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7083e-02,  5.1462e-02, -9.9246e-02],\n",
      "          [-1.6895e-02, -2.5040e-02,  1.4100e-01],\n",
      "          [-6.1714e-02,  4.2770e-03,  2.7623e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.4767e-02,  3.1637e-02,  4.0508e-02],\n",
      "          [-4.0693e-02, -6.4399e-02, -2.6980e-02],\n",
      "          [-2.1362e-02, -5.1530e-04,  1.2835e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0178e-03,  2.9637e-02,  4.0032e-02],\n",
      "          [-4.8571e-02,  8.9528e-03,  1.0645e-01],\n",
      "          [ 3.1933e-02,  3.0600e-02, -6.8633e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1266e-02, -7.2382e-02,  1.1470e-02],\n",
      "          [-7.4656e-02, -6.5107e-02, -1.0569e-01],\n",
      "          [-6.1863e-02, -6.5075e-02,  4.7083e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.2153e-02, -3.1044e-02,  7.5543e-03],\n",
      "          [-1.8244e-02, -4.8699e-02, -1.9019e-02],\n",
      "          [ 7.7998e-03, -2.4585e-02,  4.6641e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0257e-02, -9.3054e-02,  3.0237e-02],\n",
      "          [-1.3078e-01, -1.3606e-02,  1.0927e-01],\n",
      "          [ 9.2760e-02, -1.5685e-01, -1.7620e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1094e-03, -6.0375e-02,  2.7051e-02],\n",
      "          [ 3.5629e-02, -8.3381e-02,  2.0957e-02],\n",
      "          [-1.9456e-02,  6.6358e-02, -1.5806e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2093e-02, -1.6297e-02, -4.2623e-03],\n",
      "          [-2.7330e-02,  5.0205e-02, -2.0737e-02],\n",
      "          [-1.0054e-01,  6.9714e-02, -7.2591e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3327e-02,  3.7529e-02,  2.9936e-02],\n",
      "          [-1.7763e-02,  3.0106e-02, -5.0151e-02],\n",
      "          [-3.1135e-02, -1.8108e-02,  1.2754e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.2860e-02, -2.3304e-02, -1.6699e-02],\n",
      "          [-5.4807e-02, -1.0358e-02,  7.3691e-02],\n",
      "          [ 5.3515e-02,  7.9802e-02, -8.1930e-04]]],\n",
      "\n",
      "\n",
      "        [[[-7.1463e-03, -1.5484e-01, -1.0049e-01],\n",
      "          [ 2.7588e-02,  3.5805e-02,  2.9975e-02],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [ 7.9173e-02, -4.3631e-02, -1.2976e-01]]]], requires_grad=True))\n",
      "('features.2.conv.4.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.2.conv.4.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.2.conv.7.weight', Parameter containing:\n",
      "tensor([[[[-0.1333]],\n",
      "\n",
      "         [[-0.1760]],\n",
      "\n",
      "         [[ 0.3654]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5989]],\n",
      "\n",
      "         [[ 0.1559]],\n",
      "\n",
      "         [[ 0.1963]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1631]],\n",
      "\n",
      "         [[-0.4250]],\n",
      "\n",
      "         [[-0.2731]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0908]],\n",
      "\n",
      "         [[ 0.1473]],\n",
      "\n",
      "         [[ 0.4631]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4747]],\n",
      "\n",
      "         [[-0.4084]],\n",
      "\n",
      "         [[-0.1270]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1609]],\n",
      "\n",
      "         [[ 0.2315]],\n",
      "\n",
      "         [[-0.2253]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1692]],\n",
      "\n",
      "         [[-0.4602]],\n",
      "\n",
      "         [[ 0.0826]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1659]],\n",
      "\n",
      "         [[-0.0540]],\n",
      "\n",
      "         [[ 0.1121]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2377]],\n",
      "\n",
      "         [[ 0.2552]],\n",
      "\n",
      "         [[ 0.0692]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1744]],\n",
      "\n",
      "         [[ 0.2112]],\n",
      "\n",
      "         [[ 0.1370]]],\n",
      "\n",
      "\n",
      "        [[[-0.6289]],\n",
      "\n",
      "         [[-0.2710]],\n",
      "\n",
      "         [[ 0.2990]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3091]],\n",
      "\n",
      "         [[ 0.3114]],\n",
      "\n",
      "         [[ 0.3347]]]], requires_grad=True))\n",
      "('features.2.conv.8.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.2.conv.8.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.3.conv.0.weight', Parameter containing:\n",
      "tensor([[[[-0.0164]],\n",
      "\n",
      "         [[ 0.2102]],\n",
      "\n",
      "         [[ 0.2061]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1921]],\n",
      "\n",
      "         [[ 0.1494]],\n",
      "\n",
      "         [[-0.1310]]],\n",
      "\n",
      "\n",
      "        [[[-0.0746]],\n",
      "\n",
      "         [[ 0.3975]],\n",
      "\n",
      "         [[ 0.5427]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2022]],\n",
      "\n",
      "         [[-0.3119]],\n",
      "\n",
      "         [[ 0.0273]]],\n",
      "\n",
      "\n",
      "        [[[-0.0949]],\n",
      "\n",
      "         [[ 0.0357]],\n",
      "\n",
      "         [[-0.0469]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1628]],\n",
      "\n",
      "         [[-0.0943]],\n",
      "\n",
      "         [[-0.0478]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0801]],\n",
      "\n",
      "         [[ 0.0019]],\n",
      "\n",
      "         [[-0.1376]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0036]],\n",
      "\n",
      "         [[ 0.0356]],\n",
      "\n",
      "         [[ 0.0777]]],\n",
      "\n",
      "\n",
      "        [[[-0.2129]],\n",
      "\n",
      "         [[-0.0171]],\n",
      "\n",
      "         [[ 0.0626]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0987]],\n",
      "\n",
      "         [[-0.1221]],\n",
      "\n",
      "         [[ 0.0935]]],\n",
      "\n",
      "\n",
      "        [[[-0.0044]],\n",
      "\n",
      "         [[ 0.1522]],\n",
      "\n",
      "         [[-0.1894]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0308]],\n",
      "\n",
      "         [[ 0.1565]],\n",
      "\n",
      "         [[-0.2732]]]], requires_grad=True))\n",
      "('features.3.conv.1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.3.conv.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.3.conv.3.weight', Parameter containing:\n",
      "tensor([[[[ 1.8445e-02,  4.3925e-03, -8.4489e-02],\n",
      "          [ 9.0685e-02, -7.7047e-02,  5.0108e-02],\n",
      "          [-6.9420e-02,  1.4996e-02,  9.1624e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2485e-02, -3.1144e-02, -7.5113e-03],\n",
      "          [-2.9686e-02, -2.2426e-02, -4.6777e-02],\n",
      "          [ 3.2967e-03, -1.4315e-02, -3.0336e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7696e-02,  7.5872e-02, -1.0772e-02],\n",
      "          [ 6.4453e-02,  6.8912e-02, -9.3114e-03],\n",
      "          [-6.4860e-03,  2.5139e-02, -6.3688e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.7006e-02,  5.7770e-02,  8.4553e-02],\n",
      "          [ 3.2161e-02, -8.3586e-02, -2.0308e-02],\n",
      "          [-7.5940e-02, -1.3079e-01, -5.9324e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.4095e-02, -6.1618e-02, -1.7328e-02],\n",
      "          [ 1.6462e-02,  5.4434e-02,  6.2551e-02],\n",
      "          [ 2.6431e-02, -1.1375e-01,  2.5399e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.2589e-03,  2.5283e-02, -2.1858e-02],\n",
      "          [-2.7098e-02, -1.1247e-01, -4.8998e-02],\n",
      "          [-1.2540e-01,  7.1686e-02,  7.3355e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.2187e-02, -3.3175e-02, -1.4899e-02],\n",
      "          [-2.6481e-02,  6.4055e-02,  3.7317e-02],\n",
      "          [ 4.7288e-03,  1.8802e-02, -1.2216e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0726e-03, -3.1560e-02, -1.0229e-01],\n",
      "          [ 5.8127e-02,  3.7438e-02,  1.8574e-02],\n",
      "          [ 6.8452e-03, -3.5223e-02, -6.9329e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.3123e-02, -4.7848e-04,  1.0495e-02],\n",
      "          [-9.7686e-03,  4.6396e-03,  5.5942e-02],\n",
      "          [ 2.5036e-02, -2.6671e-02, -3.8235e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9545e-02,  1.4830e-01,  4.8213e-02],\n",
      "          [-4.6542e-02, -8.4132e-03,  1.0962e-01],\n",
      "          [-3.8805e-02,  2.3947e-02, -5.7848e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0244e-03,  4.4109e-04,  2.2479e-02],\n",
      "          [ 5.0990e-02, -3.7710e-02, -6.4359e-02],\n",
      "          [ 8.5578e-02, -2.4416e-02,  1.9109e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.8445e-02, -8.9146e-02,  4.6359e-03],\n",
      "          [-5.2027e-02,  5.3814e-02,  3.8058e-02],\n",
      "          [ 6.3724e-02,  1.1788e-02,  2.2803e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.3689e-02,  7.0458e-02, -2.1679e-02],\n",
      "          [ 3.7868e-02, -1.0988e-01,  7.2853e-03],\n",
      "          [-2.5788e-02,  4.2535e-02,  3.0198e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0043e-01, -9.2144e-02,  2.2175e-02],\n",
      "          [ 2.3529e-02,  4.7112e-02,  2.8496e-02],\n",
      "          [-4.9463e-02, -7.9430e-02,  2.4666e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1443e-02,  3.6557e-02,  3.2939e-02],\n",
      "          [ 6.1703e-03,  9.2552e-03, -3.1056e-02],\n",
      "          [ 6.1057e-03,  2.7610e-02, -2.9871e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3040e-02, -2.8606e-02, -4.2416e-02],\n",
      "          [-6.1338e-02,  1.6601e-02,  8.5891e-02],\n",
      "          [-1.2876e-02,  3.5288e-03, -6.1741e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.8061e-02,  3.9574e-02, -6.2580e-02],\n",
      "          [ 1.7883e-02,  5.8815e-02, -1.9960e-02],\n",
      "          [ 3.2157e-02,  5.2687e-02,  2.6940e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8263e-03, -8.4104e-02,  1.1441e-02],\n",
      "          [ 2.9343e-02,  5.7952e-02, -4.4232e-02],\n",
      "          [-7.3653e-02,  4.7273e-02, -8.2750e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.5469e-03,  8.0062e-02,  4.8835e-02],\n",
      "          [-4.2024e-04, -2.5805e-03,  4.2026e-02],\n",
      "          [-2.2625e-02, -6.3085e-02,  3.3459e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9607e-02,  8.3091e-02,  4.4554e-02],\n",
      "          [ 1.0111e-03,  7.7161e-03, -5.6192e-03],\n",
      "          [-2.9996e-02, -6.0379e-02, -1.4476e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.9927e-02, -1.1117e-01,  7.7272e-02],\n",
      "          [ 6.2863e-02,  6.6775e-02, -5.3522e-02],\n",
      "          [ 6.3101e-02,  1.2695e-02,  7.0588e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0273e-01,  5.0047e-02, -4.3353e-02],\n",
      "          [ 1.1766e-01,  9.2743e-02,  6.5785e-05],\n",
      "          [-3.5961e-02,  2.9505e-02,  7.0161e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.8076e-02, -2.8948e-02, -4.7890e-02],\n",
      "          [-7.9982e-02,  1.8683e-02,  7.3071e-03],\n",
      "          [ 2.7323e-03, -7.1045e-02, -1.0233e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2539e-03,  2.1987e-02, -5.5010e-02],\n",
      "          [ 4.5674e-03, -5.7597e-02,  2.5540e-02],\n",
      "          [-9.7162e-02,  6.4420e-02,  2.1150e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6077e-02, -9.7998e-02,  1.4395e-02],\n",
      "          [-4.7022e-03, -1.7491e-02, -4.0057e-02],\n",
      "          [ 5.8793e-03, -5.7086e-02,  4.7743e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.5324e-03, -1.1731e-02, -7.4143e-02],\n",
      "          [ 1.3227e-01, -6.0736e-02,  4.0740e-02],\n",
      "          [ 1.4012e-01, -1.6036e-02,  7.6839e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9456e-02,  5.7930e-02, -7.1556e-03],\n",
      "          [ 1.3736e-03,  8.3174e-03,  2.9432e-02],\n",
      "          [ 7.9574e-03,  1.9208e-02,  2.6479e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0453e-03, -9.7812e-02,  5.4610e-02],\n",
      "          [ 9.3623e-04, -1.4033e-02,  1.1753e-01],\n",
      "          [-2.8548e-02, -2.8540e-02,  3.2321e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1116e-02, -9.7249e-03, -1.3253e-01],\n",
      "          [ 6.2409e-02, -1.8543e-02,  2.8685e-02],\n",
      "          [-1.0267e-02,  1.3913e-01, -5.6974e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7568e-02, -2.7784e-02, -5.6502e-03],\n",
      "          [-2.9502e-02, -2.5503e-03,  5.5223e-03],\n",
      "          [-3.5323e-02,  3.0317e-02,  1.3300e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.2186e-02,  1.1997e-01,  2.5360e-02],\n",
      "          [ 1.0004e-01,  1.9921e-02, -6.2433e-03],\n",
      "          [ 8.9886e-03,  4.7929e-02,  7.8502e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6830e-02,  5.7273e-03, -2.4068e-02],\n",
      "          [ 7.6828e-04,  1.1076e-02,  4.2036e-02],\n",
      "          [-3.8390e-02,  4.3473e-02, -6.0303e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.0371e-02,  1.1502e-02,  2.9050e-02],\n",
      "          [ 4.7608e-02, -2.0403e-03,  9.9151e-03],\n",
      "          [-8.7146e-03,  3.7649e-02, -7.1457e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3709e-02, -4.4033e-02,  3.6377e-02],\n",
      "          [-3.7797e-02, -4.2935e-02, -4.9704e-02],\n",
      "          [ 1.5172e-02, -2.1751e-03,  1.0838e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.8399e-02,  7.1194e-03, -3.3296e-02],\n",
      "          [ 2.3784e-02,  5.3302e-03,  3.3046e-02],\n",
      "          [ 4.4222e-02, -3.7896e-03,  2.4502e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2844e-01, -1.1420e-02,  5.5478e-02],\n",
      "          [ 2.0646e-02,  1.0599e-01, -2.8740e-02],\n",
      "          [ 1.0425e-02,  1.0149e-02,  1.3768e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1951e-02, -8.3335e-02, -1.5327e-02],\n",
      "          [ 3.0096e-03, -1.0073e-01,  5.8691e-02],\n",
      "          [-9.5471e-02, -9.0582e-03,  3.3607e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.6691e-02,  4.0101e-02,  1.5789e-02],\n",
      "          [ 8.6126e-02,  5.1212e-02, -2.5302e-02],\n",
      "          [-2.7693e-02, -5.2433e-02,  1.2455e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.4517e-02, -3.7413e-02,  3.6005e-02],\n",
      "          [-2.0633e-02, -3.8292e-02,  1.0663e-02],\n",
      "          [-2.9805e-02,  7.4025e-02, -8.0739e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.7076e-02, -4.8862e-02,  8.5310e-02],\n",
      "          [ 2.3166e-02,  1.1365e-02,  1.4498e-02],\n",
      "          [ 2.3754e-02, -1.2273e-01, -2.9220e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1286e-03, -5.1266e-02,  1.7092e-03],\n",
      "          [-2.0523e-02,  4.7991e-03, -4.4257e-02],\n",
      "          [-9.0740e-02,  6.9831e-02, -6.4907e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5604e-02, -3.8960e-02, -3.3210e-03],\n",
      "          [-2.1528e-02,  8.4710e-02,  5.3622e-02],\n",
      "          [-1.3210e-02, -4.5084e-02, -4.3626e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.1986e-02,  3.0988e-02, -2.1183e-02],\n",
      "          [-4.8637e-02, -5.9039e-02,  1.3476e-02],\n",
      "          [ 5.2429e-03, -4.0605e-02,  1.7301e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.8915e-02, -1.2637e-02,  2.7142e-02],\n",
      "          [ 3.9224e-03,  6.3224e-02,  6.4164e-02],\n",
      "          [-6.0219e-02, -3.5681e-02,  6.5346e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2347e-02, -1.0104e-01, -6.5080e-02],\n",
      "          [-6.9972e-03,  4.1297e-02,  7.2281e-02],\n",
      "          [-2.3874e-02,  1.1425e-02, -3.8809e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.5847e-02,  8.8030e-03, -1.8419e-02],\n",
      "          [-9.1242e-03,  3.8388e-02, -9.1214e-03],\n",
      "          [ 3.3701e-02,  5.0563e-02,  6.1457e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.2663e-02, -9.2763e-02,  1.1163e-01],\n",
      "          [ 1.3565e-02, -1.1130e-02, -1.1085e-01],\n",
      "          [-3.1806e-03,  2.7008e-02, -1.1537e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5040e-02,  3.5924e-03, -2.4140e-02],\n",
      "          [ 4.5683e-02, -6.7098e-02, -1.9915e-02],\n",
      "          [-3.8965e-02, -3.3414e-02,  2.6285e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.8798e-02, -1.5474e-02,  5.1579e-02],\n",
      "          [ 3.8978e-02, -9.2839e-03, -1.0101e-02],\n",
      "          [ 1.9567e-02,  4.9828e-02,  1.3955e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2912e-02, -4.6419e-02, -7.1105e-02],\n",
      "          [-2.9126e-02,  8.9840e-02,  6.8564e-02],\n",
      "          [ 9.6154e-02,  6.0821e-02, -1.6866e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.4042e-02, -7.9914e-02, -9.7949e-03],\n",
      "          [-2.9101e-02, -3.2266e-02,  3.4247e-02],\n",
      "          [-3.7452e-02,  3.9324e-02, -6.7814e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4114e-02, -1.5232e-01, -1.6989e-02],\n",
      "          [ 1.6323e-01, -8.8696e-03, -7.9431e-02],\n",
      "          [-2.8537e-02,  4.0208e-02,  3.9585e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0097e-01,  4.0017e-02, -2.9803e-03],\n",
      "          [-1.0207e-01, -4.2786e-02,  2.4191e-02],\n",
      "          [-5.3157e-02, -8.4484e-02,  5.3281e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5112e-02, -4.1442e-02, -1.3721e-02],\n",
      "          [-6.3019e-02,  2.8808e-02, -4.7601e-03],\n",
      "          [ 6.4796e-02,  6.2706e-02,  4.2170e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9822e-02, -1.3790e-02,  7.5005e-02],\n",
      "          [ 8.9687e-02,  7.1830e-02,  7.3261e-02],\n",
      "          [ 1.4062e-02, -2.5838e-02, -8.9104e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3292e-02, -5.6041e-02,  2.0989e-04],\n",
      "          [ 3.9615e-02, -4.3742e-03, -2.9833e-03],\n",
      "          [-1.2421e-01, -1.1836e-01, -5.6488e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.0315e-02,  3.6499e-02, -1.5654e-02],\n",
      "          [ 8.1321e-02,  4.0319e-03, -9.2994e-02],\n",
      "          [ 6.4810e-03, -7.9502e-02, -8.2925e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4478e-02,  4.2191e-02, -8.9147e-02],\n",
      "          [ 8.6759e-02,  2.0196e-02, -3.8292e-02],\n",
      "          [ 7.6631e-02,  2.0166e-02, -5.5932e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.0131e-02,  9.4868e-02,  2.9960e-02],\n",
      "          [ 1.2387e-03,  2.6368e-02,  1.7075e-02],\n",
      "          [ 3.6071e-02,  1.1378e-01, -4.1531e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6885e-02,  3.4811e-03,  8.6611e-02],\n",
      "          [ 3.2860e-02,  2.7315e-02,  9.9991e-03],\n",
      "          [ 9.7021e-02, -2.7484e-02, -3.8849e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6260e-02,  1.5144e-02,  2.1297e-02],\n",
      "          [-5.5734e-02, -2.2281e-02, -4.5922e-02],\n",
      "          [ 3.1241e-02,  3.6431e-02,  5.3868e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7875e-02, -3.4996e-02,  1.2925e-02],\n",
      "          [-4.9765e-02, -6.7075e-02, -1.0042e-01],\n",
      "          [-4.4665e-02, -2.8989e-02, -1.0375e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.9299e-02,  2.7542e-02,  4.0132e-03],\n",
      "          [-2.3076e-03,  1.7914e-02,  3.8456e-02],\n",
      "          [-2.5583e-02, -4.4729e-02, -4.1312e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.3409e-02,  3.6069e-02,  6.7901e-03],\n",
      "          [ 1.0108e-01, -9.1530e-02,  7.4947e-02],\n",
      "          [ 3.7746e-02, -1.2681e-01, -1.8223e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6422e-02,  6.7327e-02, -8.5740e-02],\n",
      "          [ 1.6030e-02,  3.1244e-02, -3.4100e-02],\n",
      "          [-5.8085e-03, -1.0359e-01, -9.5346e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.2618e-02,  1.3470e-02, -9.1568e-02],\n",
      "          [-2.4216e-02,  5.2658e-02,  7.4303e-02],\n",
      "          [-3.1868e-02,  2.9449e-02, -3.5142e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5984e-03, -3.3818e-02,  1.1600e-02],\n",
      "          [ 7.8181e-02,  3.4049e-02, -9.1704e-03],\n",
      "          [-5.4969e-02, -6.4363e-03,  2.2310e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0500e-03,  2.8873e-02, -4.1928e-03],\n",
      "          [-1.0494e-02,  8.4497e-02, -2.0632e-03],\n",
      "          [-6.9602e-02, -5.1425e-02, -2.5123e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9635e-02, -1.3193e-02,  1.6896e-02],\n",
      "          [ 4.9609e-02,  1.0286e-01, -3.5667e-02],\n",
      "          [-2.2172e-02,  3.3059e-02, -8.1371e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4360e-02,  2.0235e-02, -2.4903e-02],\n",
      "          [-5.8870e-02,  3.6883e-02, -8.5483e-02],\n",
      "          [-8.0087e-02,  3.8116e-02, -3.1034e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0151e-01, -4.6084e-02, -1.8095e-02],\n",
      "          [ 1.6021e-01,  1.8282e-03, -2.2173e-03],\n",
      "          [ 9.3576e-02, -5.2131e-03,  5.9359e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0444e-02,  6.3089e-02,  6.5738e-02],\n",
      "          [-3.8253e-02,  5.7899e-02, -5.7378e-02],\n",
      "          [-2.5700e-02, -8.6231e-02, -6.8528e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.4964e-03, -2.7671e-02,  6.5192e-02],\n",
      "          [-8.7836e-02, -1.0057e-01, -9.3203e-03],\n",
      "          [ 7.7709e-02, -1.3459e-02,  1.2506e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1052e-02,  5.3578e-02, -4.5574e-03],\n",
      "          [-1.0802e-03,  3.4851e-03, -3.6252e-02],\n",
      "          [-8.2496e-02, -6.1076e-02,  2.3067e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0965e-02,  1.9507e-02, -2.3554e-02],\n",
      "          [-7.6888e-02,  1.4980e-02,  8.0634e-02],\n",
      "          [ 3.3648e-02, -1.8053e-02, -3.7490e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.6399e-03, -3.8819e-02,  6.8236e-02],\n",
      "          [ 1.9643e-02,  3.9728e-02,  4.8812e-02],\n",
      "          [-2.3696e-03,  6.3823e-02,  7.5312e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.6310e-04,  1.0746e-02,  4.8317e-02],\n",
      "          [ 3.5649e-02,  1.1210e-01,  4.1415e-02],\n",
      "          [ 1.4856e-02,  8.9098e-03,  7.5511e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.9348e-02,  3.1932e-02,  1.2854e-02],\n",
      "          [-2.0479e-02,  3.7339e-02,  3.2286e-02],\n",
      "          [ 1.4642e-02, -2.5179e-03, -1.8573e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0018e-02, -1.6549e-02,  3.1759e-02],\n",
      "          [-9.9108e-02, -8.4192e-02,  5.0699e-03],\n",
      "          [ 5.6184e-02,  5.7323e-03,  5.0729e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8244e-02, -3.6103e-02, -8.1423e-02],\n",
      "          [-6.0721e-02,  4.8316e-02, -5.3246e-02],\n",
      "          [-1.9743e-03,  3.1256e-02, -3.2227e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0527e-02,  2.0546e-02, -7.2374e-03],\n",
      "          [-3.7136e-02,  5.2262e-02, -9.3537e-02],\n",
      "          [ 5.7516e-02, -9.1257e-02,  6.7250e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0177e-01, -2.8328e-02,  7.8792e-03],\n",
      "          [-5.0547e-02,  2.9818e-02,  1.3113e-02],\n",
      "          [-2.9848e-02, -3.9019e-03, -6.5840e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0163e-02, -8.8474e-02,  6.9718e-02],\n",
      "          [-1.6539e-02, -4.9338e-03,  4.0460e-02],\n",
      "          [-2.0683e-02,  3.7012e-02, -2.0099e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6329e-02, -2.8912e-02,  9.0919e-04],\n",
      "          [-1.0105e-02,  9.6403e-03,  2.7470e-02],\n",
      "          [ 3.8304e-02,  7.5569e-02,  7.7218e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4395e-02, -3.5783e-02, -2.3207e-02],\n",
      "          [-1.2730e-01,  4.2595e-02, -3.7158e-02],\n",
      "          [ 8.2728e-02,  3.9627e-02, -4.1663e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.3719e-02,  5.8661e-03, -6.1124e-03],\n",
      "          [ 2.3776e-04, -2.1126e-03,  4.5071e-02],\n",
      "          [ 7.0119e-02, -5.6801e-02, -4.6706e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7477e-02,  5.4150e-02, -1.6280e-02],\n",
      "          [ 7.7798e-03,  5.1252e-02,  3.0298e-02],\n",
      "          [ 6.2013e-02,  7.0943e-02,  1.2832e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.0849e-02, -6.5099e-02, -8.6870e-02],\n",
      "          [ 3.7240e-03, -3.7445e-02, -8.2736e-02],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [-1.6878e-03, -1.6255e-02,  6.7014e-03]]]], requires_grad=True))\n",
      "('features.3.conv.4.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.3.conv.4.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.3.conv.7.weight', Parameter containing:\n",
      "tensor([[[[-0.2918]],\n",
      "\n",
      "         [[ 0.0573]],\n",
      "\n",
      "         [[-0.1117]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1099]],\n",
      "\n",
      "         [[ 0.0755]],\n",
      "\n",
      "         [[ 0.2870]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1135]],\n",
      "\n",
      "         [[ 0.1760]],\n",
      "\n",
      "         [[-0.0134]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3617]],\n",
      "\n",
      "         [[-0.2953]],\n",
      "\n",
      "         [[ 0.1151]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1309]],\n",
      "\n",
      "         [[ 0.0227]],\n",
      "\n",
      "         [[ 0.0765]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0953]],\n",
      "\n",
      "         [[ 0.3162]],\n",
      "\n",
      "         [[-0.1844]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0131]],\n",
      "\n",
      "         [[ 0.1332]],\n",
      "\n",
      "         [[-0.1527]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0984]],\n",
      "\n",
      "         [[ 0.3250]],\n",
      "\n",
      "         [[ 0.0609]]],\n",
      "\n",
      "\n",
      "        [[[-0.1075]],\n",
      "\n",
      "         [[-0.7923]],\n",
      "\n",
      "         [[ 0.0808]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0614]],\n",
      "\n",
      "         [[-0.0024]],\n",
      "\n",
      "         [[-0.0550]]],\n",
      "\n",
      "\n",
      "        [[[-0.4001]],\n",
      "\n",
      "         [[-0.2944]],\n",
      "\n",
      "         [[ 0.5267]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2137]],\n",
      "\n",
      "         [[ 0.4749]],\n",
      "\n",
      "         [[ 0.3939]]]], requires_grad=True))\n",
      "('features.3.conv.8.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.3.conv.8.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.4.conv.0.weight', Parameter containing:\n",
      "tensor([[[[-0.3280]],\n",
      "\n",
      "         [[-0.0800]],\n",
      "\n",
      "         [[-0.0641]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1855]],\n",
      "\n",
      "         [[ 0.2095]],\n",
      "\n",
      "         [[ 0.1272]]],\n",
      "\n",
      "\n",
      "        [[[-0.2544]],\n",
      "\n",
      "         [[ 0.0249]],\n",
      "\n",
      "         [[ 0.1276]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0521]],\n",
      "\n",
      "         [[-0.1309]],\n",
      "\n",
      "         [[ 0.0870]]],\n",
      "\n",
      "\n",
      "        [[[-0.0878]],\n",
      "\n",
      "         [[ 0.0326]],\n",
      "\n",
      "         [[-0.1344]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0190]],\n",
      "\n",
      "         [[-0.0338]],\n",
      "\n",
      "         [[-0.2997]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0805]],\n",
      "\n",
      "         [[-0.0081]],\n",
      "\n",
      "         [[-0.0702]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2070]],\n",
      "\n",
      "         [[-0.1529]],\n",
      "\n",
      "         [[ 0.0141]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1008]],\n",
      "\n",
      "         [[-0.1883]],\n",
      "\n",
      "         [[ 0.0242]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0260]],\n",
      "\n",
      "         [[-0.0747]],\n",
      "\n",
      "         [[ 0.0753]]],\n",
      "\n",
      "\n",
      "        [[[-0.0251]],\n",
      "\n",
      "         [[-0.1561]],\n",
      "\n",
      "         [[ 0.1604]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1269]],\n",
      "\n",
      "         [[-0.0458]],\n",
      "\n",
      "         [[-0.0426]]]], requires_grad=True))\n",
      "('features.4.conv.1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.4.conv.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.4.conv.3.weight', Parameter containing:\n",
      "tensor([[[[ 4.5894e-02,  3.5751e-02,  4.3033e-03,  2.6125e-02, -1.3166e-02],\n",
      "          [ 8.1230e-03, -2.4576e-02, -2.3648e-02, -1.5498e-02, -2.7246e-03],\n",
      "          [ 3.7760e-02,  4.5918e-02,  2.5671e-02,  3.1595e-02,  2.8669e-02],\n",
      "          [ 2.5387e-02, -3.2451e-02,  6.8749e-03,  4.0476e-02,  3.8802e-02],\n",
      "          [ 1.2562e-02, -6.9767e-03, -1.8598e-02,  1.9044e-02,  2.3752e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.7457e-03,  2.6194e-02, -1.8432e-02, -2.3932e-02,  1.8702e-02],\n",
      "          [ 1.9880e-02, -4.5787e-02,  6.9387e-03, -2.7571e-02, -5.4233e-02],\n",
      "          [-2.9857e-02, -5.1993e-02, -8.2028e-03, -6.3285e-03, -2.2272e-03],\n",
      "          [ 1.4267e-02, -2.6467e-02, -4.0729e-02,  1.7729e-02,  2.0047e-02],\n",
      "          [-2.4352e-02,  1.2008e-02, -4.0723e-02, -3.9619e-04,  2.2058e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.6153e-02,  4.0786e-02,  1.2169e-02, -4.3889e-02, -2.2477e-02],\n",
      "          [-2.3698e-02, -5.7899e-02,  1.0562e-02,  4.1368e-02,  1.1105e-02],\n",
      "          [-3.8836e-02,  5.4973e-04, -3.6438e-02,  7.6650e-03,  3.2624e-02],\n",
      "          [ 3.1092e-02,  1.2297e-02,  1.6056e-03,  5.4499e-03,  1.6228e-02],\n",
      "          [ 5.7698e-02, -3.9944e-02,  2.3260e-02, -5.8159e-02,  8.8640e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.2273e-02, -4.4244e-03,  3.6418e-03,  3.5109e-02, -3.0240e-03],\n",
      "          [ 4.2171e-03,  5.0560e-02,  8.8858e-03,  5.3087e-02,  2.0255e-02],\n",
      "          [ 7.4371e-03,  3.9982e-03,  3.9643e-02,  2.4345e-02, -7.2210e-03],\n",
      "          [ 1.3083e-02,  2.4151e-02, -1.0763e-02, -1.0821e-02,  4.0263e-02],\n",
      "          [ 3.8022e-02, -8.4264e-03, -1.0152e-02, -4.9439e-02,  5.0035e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9104e-02, -7.7807e-03,  3.6618e-02,  5.1313e-03,  1.6604e-02],\n",
      "          [ 1.4997e-02,  4.0885e-05,  2.2304e-02,  2.2421e-02, -2.3989e-02],\n",
      "          [ 8.7925e-02,  1.5979e-03, -3.4880e-04, -4.5881e-04,  3.2492e-02],\n",
      "          [ 3.0993e-02, -3.4522e-02, -5.6901e-02, -2.2264e-02, -4.3035e-03],\n",
      "          [ 4.3656e-02, -2.2100e-02,  2.0125e-02, -4.6237e-02,  1.8378e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.7839e-02, -9.1052e-03,  1.8667e-02, -5.3711e-02,  1.7708e-02],\n",
      "          [ 2.0518e-02,  1.9517e-02,  4.1466e-02, -1.9477e-02,  1.5558e-02],\n",
      "          [-1.6711e-02,  3.0075e-03,  3.7933e-02, -2.1141e-02,  2.9565e-02],\n",
      "          [ 3.5116e-02,  1.1886e-02,  4.3157e-02,  1.5902e-02, -5.4422e-03],\n",
      "          [-2.7047e-03, -1.6489e-02,  1.1278e-02,  6.8383e-03,  1.7493e-04]]]],\n",
      "       requires_grad=True))\n",
      "('features.4.conv.4.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.4.conv.4.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.4.conv.5.fc.0.weight', Parameter containing:\n",
      "tensor([[-0.0107,  0.0059,  0.0135,  ...,  0.0027,  0.0058, -0.0110],\n",
      "        [-0.0192,  0.0249, -0.0044,  ...,  0.0024,  0.0129,  0.0018],\n",
      "        [ 0.0028, -0.0135,  0.0019,  ...,  0.0100, -0.0138, -0.0060],\n",
      "        ...,\n",
      "        [-0.0029, -0.0163, -0.0091,  ...,  0.0057, -0.0226, -0.0018],\n",
      "        [ 0.0056,  0.0007, -0.0071,  ...,  0.0079,  0.0172, -0.0076],\n",
      "        [-0.0043,  0.0040,  0.0057,  ...,  0.0089, -0.0038,  0.0022]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       requires_grad=True))\n",
      "('features.4.conv.5.fc.2.weight', Parameter containing:\n",
      "tensor([[ 0.0057, -0.0229,  0.0115,  ...,  0.0023,  0.0105, -0.0082],\n",
      "        [-0.0011, -0.0116, -0.0025,  ..., -0.0033, -0.0066, -0.0035],\n",
      "        [-0.0012,  0.0097,  0.0007,  ..., -0.0156,  0.0040, -0.0043],\n",
      "        ...,\n",
      "        [ 0.0113,  0.0004, -0.0057,  ..., -0.0025,  0.0078, -0.0096],\n",
      "        [-0.0127,  0.0181,  0.0079,  ..., -0.0033,  0.0027,  0.0019],\n",
      "        [-0.0231,  0.0030, -0.0002,  ...,  0.0192,  0.0081,  0.0008]],\n",
      "       requires_grad=True))\n",
      "('features.4.conv.7.weight', Parameter containing:\n",
      "tensor([[[[-0.3161]],\n",
      "\n",
      "         [[-0.0794]],\n",
      "\n",
      "         [[ 0.1004]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2945]],\n",
      "\n",
      "         [[-0.2140]],\n",
      "\n",
      "         [[ 0.0653]]],\n",
      "\n",
      "\n",
      "        [[[-0.0174]],\n",
      "\n",
      "         [[ 0.5130]],\n",
      "\n",
      "         [[-0.3500]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2474]],\n",
      "\n",
      "         [[ 0.1555]],\n",
      "\n",
      "         [[ 0.0946]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0303]],\n",
      "\n",
      "         [[ 0.1128]],\n",
      "\n",
      "         [[ 0.1146]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3643]],\n",
      "\n",
      "         [[-0.0116]],\n",
      "\n",
      "         [[-0.0159]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0279]],\n",
      "\n",
      "         [[ 0.1282]],\n",
      "\n",
      "         [[-0.0092]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1601]],\n",
      "\n",
      "         [[ 0.2027]],\n",
      "\n",
      "         [[ 0.0502]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2240]],\n",
      "\n",
      "         [[ 0.2758]],\n",
      "\n",
      "         [[-0.4464]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2248]],\n",
      "\n",
      "         [[ 0.2782]],\n",
      "\n",
      "         [[ 0.2805]]],\n",
      "\n",
      "\n",
      "        [[[-0.1145]],\n",
      "\n",
      "         [[-0.2899]],\n",
      "\n",
      "         [[-0.0070]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4311]],\n",
      "\n",
      "         [[ 0.0010]],\n",
      "\n",
      "         [[ 0.1447]]]], requires_grad=True))\n",
      "('features.4.conv.8.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True))\n",
      "('features.4.conv.8.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.5.conv.0.weight', Parameter containing:\n",
      "tensor([[[[-0.1103]],\n",
      "\n",
      "         [[ 0.1694]],\n",
      "\n",
      "         [[-0.1506]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0222]],\n",
      "\n",
      "         [[-0.0606]],\n",
      "\n",
      "         [[-0.0169]]],\n",
      "\n",
      "\n",
      "        [[[-0.0656]],\n",
      "\n",
      "         [[ 0.0046]],\n",
      "\n",
      "         [[ 0.0446]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0859]],\n",
      "\n",
      "         [[ 0.1962]],\n",
      "\n",
      "         [[-0.0219]]],\n",
      "\n",
      "\n",
      "        [[[-0.0464]],\n",
      "\n",
      "         [[ 0.0284]],\n",
      "\n",
      "         [[ 0.0652]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0554]],\n",
      "\n",
      "         [[-0.0377]],\n",
      "\n",
      "         [[ 0.1611]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0764]],\n",
      "\n",
      "         [[-0.0018]],\n",
      "\n",
      "         [[ 0.0015]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0756]],\n",
      "\n",
      "         [[-0.0217]],\n",
      "\n",
      "         [[ 0.0124]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0034]],\n",
      "\n",
      "         [[-0.0690]],\n",
      "\n",
      "         [[ 0.0780]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0218]],\n",
      "\n",
      "         [[-0.0096]],\n",
      "\n",
      "         [[-0.0859]]],\n",
      "\n",
      "\n",
      "        [[[-0.1023]],\n",
      "\n",
      "         [[ 0.1269]],\n",
      "\n",
      "         [[-0.1560]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0093]],\n",
      "\n",
      "         [[-0.2558]],\n",
      "\n",
      "         [[-0.0318]]]], requires_grad=True))\n",
      "('features.5.conv.1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.5.conv.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.5.conv.3.weight', Parameter containing:\n",
      "tensor([[[[-2.0249e-02,  9.8037e-04, -2.6112e-02,  5.2657e-03,  2.2108e-02],\n",
      "          [ 1.5428e-03, -2.2357e-02,  2.2491e-02,  3.5620e-03,  2.8382e-02],\n",
      "          [ 3.4823e-02,  2.6174e-03,  1.3226e-02, -3.4426e-03,  2.5411e-02],\n",
      "          [-1.6269e-02, -1.7674e-02, -1.0803e-03,  1.6638e-02, -4.8235e-03],\n",
      "          [ 5.0712e-03,  1.1407e-03,  1.4539e-02,  6.9787e-03,  2.1289e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3422e-03,  1.3525e-02,  1.2996e-03,  1.3799e-03,  5.0004e-04],\n",
      "          [-1.6557e-02, -3.5605e-03, -2.1081e-02, -1.3919e-03,  1.3049e-02],\n",
      "          [ 2.9372e-02,  2.1119e-02, -8.1858e-03,  8.4548e-03, -1.5408e-03],\n",
      "          [ 3.1954e-03,  4.7855e-03,  2.0770e-02, -1.3810e-02,  1.7006e-03],\n",
      "          [ 3.8586e-03, -1.9751e-02, -2.5182e-02, -2.1290e-03,  5.7973e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.0370e-03, -7.9968e-03, -2.1554e-03, -2.0582e-02,  1.9430e-02],\n",
      "          [-1.3562e-03, -6.5196e-04,  1.3062e-03,  2.2361e-02, -1.9003e-03],\n",
      "          [-1.3804e-02, -2.9832e-02,  3.8133e-04, -2.1169e-02, -2.3897e-02],\n",
      "          [-1.1521e-02, -1.7383e-02, -8.8964e-03, -8.7195e-03,  4.4381e-04],\n",
      "          [ 1.3846e-02,  2.2815e-02, -8.0130e-03, -1.7018e-02,  3.4323e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.4033e-03,  1.4850e-02, -2.0472e-04,  3.3305e-03,  1.8904e-02],\n",
      "          [ 1.8782e-02, -1.4610e-03, -9.3268e-03, -4.2006e-02,  1.5572e-02],\n",
      "          [ 1.6287e-03, -3.6317e-02,  5.8938e-03, -3.2507e-03,  3.6083e-03],\n",
      "          [ 1.5103e-03, -1.4934e-02, -2.3626e-02,  1.2423e-02,  5.7868e-03],\n",
      "          [-3.7787e-02,  1.9209e-02, -7.8918e-03, -2.5016e-02,  5.3774e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.9645e-02, -3.4210e-02, -3.4037e-02,  1.7965e-02, -2.2660e-02],\n",
      "          [-6.0206e-05, -5.5384e-03,  3.1099e-03,  5.7948e-03,  2.4170e-02],\n",
      "          [-3.6130e-03, -7.6120e-03,  1.5381e-02,  2.6955e-02, -9.0566e-04],\n",
      "          [-2.9588e-02,  7.3583e-03,  2.1345e-02, -7.1127e-03,  2.8060e-03],\n",
      "          [ 3.3020e-03, -9.6500e-03, -9.1111e-03, -5.7569e-03,  4.6212e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4393e-03,  6.7223e-03,  2.4035e-02, -1.4847e-02,  1.6293e-02],\n",
      "          [ 9.2916e-03, -1.3617e-03,  1.0121e-02,  1.1672e-04, -1.7891e-02],\n",
      "          [-2.6818e-02,  1.0897e-02, -4.1156e-03,  2.1356e-02,  2.1663e-02],\n",
      "          [ 1.1136e-03, -3.9260e-04,  3.0107e-04,  2.2995e-03,  5.4196e-03],\n",
      "          [ 8.9111e-03,  1.7848e-04,  6.9795e-03, -1.8260e-02, -1.4024e-02]]]],\n",
      "       requires_grad=True))\n",
      "('features.5.conv.4.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.5.conv.4.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.5.conv.5.fc.0.weight', Parameter containing:\n",
      "tensor([[-5.3595e-03, -2.9576e-03, -1.5620e-02,  ..., -7.9068e-03,\n",
      "          1.4234e-02, -3.2466e-04],\n",
      "        [-6.1861e-05, -3.0427e-03,  9.3620e-03,  ..., -3.9295e-03,\n",
      "          1.9705e-02, -2.2153e-03],\n",
      "        [ 1.2499e-02,  2.0869e-03,  7.6580e-03,  ...,  1.8385e-02,\n",
      "          1.3125e-02,  4.8570e-04],\n",
      "        ...,\n",
      "        [ 4.7476e-03, -3.1866e-03,  9.1101e-03,  ..., -1.1487e-02,\n",
      "         -1.1287e-02, -6.4278e-03],\n",
      "        [-1.4241e-03,  7.2431e-03,  8.7449e-04,  ..., -2.0414e-03,\n",
      "         -1.6808e-02,  5.5311e-03],\n",
      "        [ 3.8221e-03,  1.1985e-03,  1.4314e-03,  ..., -1.5259e-02,\n",
      "          1.1123e-02, -3.6546e-03]], requires_grad=True))\n",
      "('features.5.conv.5.fc.2.weight', Parameter containing:\n",
      "tensor([[-0.0070, -0.0026, -0.0015,  ..., -0.0034, -0.0021,  0.0020],\n",
      "        [ 0.0084,  0.0021, -0.0040,  ...,  0.0068,  0.0003,  0.0056],\n",
      "        [ 0.0026,  0.0098, -0.0028,  ..., -0.0188,  0.0067, -0.0064],\n",
      "        ...,\n",
      "        [-0.0001, -0.0155, -0.0084,  ...,  0.0048,  0.0099, -0.0060],\n",
      "        [-0.0180,  0.0163,  0.0102,  ...,  0.0091,  0.0062,  0.0115],\n",
      "        [ 0.0007, -0.0249, -0.0098,  ..., -0.0074,  0.0070,  0.0057]],\n",
      "       requires_grad=True))\n",
      "('features.5.conv.7.weight', Parameter containing:\n",
      "tensor([[[[-0.1223]],\n",
      "\n",
      "         [[-0.1953]],\n",
      "\n",
      "         [[-0.0141]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0559]],\n",
      "\n",
      "         [[ 0.1327]],\n",
      "\n",
      "         [[ 0.0831]]],\n",
      "\n",
      "\n",
      "        [[[-0.0408]],\n",
      "\n",
      "         [[-0.1150]],\n",
      "\n",
      "         [[ 0.2523]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1524]],\n",
      "\n",
      "         [[ 0.4309]],\n",
      "\n",
      "         [[ 0.1390]]],\n",
      "\n",
      "\n",
      "        [[[-0.0408]],\n",
      "\n",
      "         [[-0.2953]],\n",
      "\n",
      "         [[-0.3241]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2158]],\n",
      "\n",
      "         [[-0.1939]],\n",
      "\n",
      "         [[-0.1440]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.2148]],\n",
      "\n",
      "         [[-0.1158]],\n",
      "\n",
      "         [[ 0.0362]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1042]],\n",
      "\n",
      "         [[-0.0967]],\n",
      "\n",
      "         [[-0.1938]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3667]],\n",
      "\n",
      "         [[ 0.2513]],\n",
      "\n",
      "         [[-0.2650]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0451]],\n",
      "\n",
      "         [[ 0.0214]],\n",
      "\n",
      "         [[ 0.0490]]],\n",
      "\n",
      "\n",
      "        [[[-0.3620]],\n",
      "\n",
      "         [[-0.4030]],\n",
      "\n",
      "         [[ 0.1157]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1153]],\n",
      "\n",
      "         [[ 0.3043]],\n",
      "\n",
      "         [[ 0.1138]]]], requires_grad=True))\n",
      "('features.5.conv.8.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True))\n",
      "('features.5.conv.8.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.6.conv.0.weight', Parameter containing:\n",
      "tensor([[[[ 0.1067]],\n",
      "\n",
      "         [[-0.0669]],\n",
      "\n",
      "         [[ 0.0666]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0075]],\n",
      "\n",
      "         [[ 0.1888]],\n",
      "\n",
      "         [[ 0.0557]]],\n",
      "\n",
      "\n",
      "        [[[-0.0103]],\n",
      "\n",
      "         [[-0.1309]],\n",
      "\n",
      "         [[ 0.2148]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0012]],\n",
      "\n",
      "         [[ 0.0593]],\n",
      "\n",
      "         [[ 0.1370]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0568]],\n",
      "\n",
      "         [[ 0.0236]],\n",
      "\n",
      "         [[-0.0798]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0036]],\n",
      "\n",
      "         [[-0.1205]],\n",
      "\n",
      "         [[-0.0122]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0164]],\n",
      "\n",
      "         [[ 0.0587]],\n",
      "\n",
      "         [[ 0.0738]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1090]],\n",
      "\n",
      "         [[ 0.0514]],\n",
      "\n",
      "         [[ 0.0268]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1005]],\n",
      "\n",
      "         [[-0.0572]],\n",
      "\n",
      "         [[ 0.0566]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1045]],\n",
      "\n",
      "         [[-0.0145]],\n",
      "\n",
      "         [[-0.0003]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0047]],\n",
      "\n",
      "         [[-0.0784]],\n",
      "\n",
      "         [[-0.0901]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0311]],\n",
      "\n",
      "         [[ 0.0869]],\n",
      "\n",
      "         [[-0.1051]]]], requires_grad=True))\n",
      "('features.6.conv.1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.6.conv.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.6.conv.3.weight', Parameter containing:\n",
      "tensor([[[[-3.0408e-02,  1.8488e-02,  1.4570e-02,  1.8836e-02,  1.1932e-02],\n",
      "          [-9.2984e-03, -1.3201e-02,  4.4023e-03,  5.7269e-03, -3.0383e-02],\n",
      "          [-6.2894e-03, -2.6870e-02,  7.0349e-03,  2.8938e-02, -2.7618e-02],\n",
      "          [-2.2238e-02,  9.7946e-03,  1.2889e-02, -2.0092e-02, -1.3442e-02],\n",
      "          [ 2.0144e-02,  2.2610e-02, -3.7477e-03,  8.9004e-03,  1.6692e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8208e-02,  2.6631e-03,  3.8165e-02,  2.3187e-03, -2.3002e-04],\n",
      "          [-2.2641e-03,  1.8557e-02,  2.2906e-02, -5.5245e-03,  1.0839e-02],\n",
      "          [-2.0427e-02,  3.9124e-03,  1.1378e-02,  2.1728e-02, -1.1027e-02],\n",
      "          [ 1.8778e-02,  1.1799e-02, -1.3451e-03,  2.8886e-03, -1.1429e-02],\n",
      "          [ 3.9800e-03,  2.1491e-03, -6.9074e-03, -4.6477e-03,  7.7722e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.8509e-03, -2.4685e-02, -1.1758e-02,  1.8648e-02,  8.0974e-03],\n",
      "          [-1.0430e-02,  2.5610e-02, -5.3351e-03, -9.6395e-03, -8.7327e-04],\n",
      "          [ 4.1304e-03,  1.7777e-02, -1.3562e-02,  2.4978e-02,  4.1294e-04],\n",
      "          [ 7.0920e-04,  2.2239e-02,  1.6459e-04, -1.4201e-02, -5.5195e-03],\n",
      "          [-2.8030e-03, -2.1793e-03, -6.3166e-04, -3.8215e-02, -3.9589e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-8.6791e-03, -1.4123e-02, -1.7094e-02, -1.2117e-02, -1.7841e-02],\n",
      "          [ 2.2213e-02,  8.4175e-03,  6.7766e-04,  2.2868e-02, -1.7148e-02],\n",
      "          [ 1.6252e-02, -2.2028e-02, -1.5936e-02,  2.4373e-02,  3.5146e-02],\n",
      "          [-9.8262e-03,  2.2923e-02, -1.9739e-03,  3.3990e-02, -2.1793e-03],\n",
      "          [-9.2118e-03,  2.7235e-02,  7.3620e-03, -5.6846e-03,  1.2247e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9729e-02, -8.1892e-05, -6.6695e-04,  1.5721e-02,  5.9810e-03],\n",
      "          [ 2.1826e-02,  6.2679e-03, -3.5409e-03, -1.6628e-02, -4.8927e-03],\n",
      "          [ 1.9642e-02, -4.1866e-03,  8.5625e-03,  1.9778e-02, -1.2307e-02],\n",
      "          [ 1.4139e-02,  2.1817e-02, -1.3599e-02,  1.9716e-02, -4.6727e-03],\n",
      "          [ 1.3813e-02,  3.3200e-02, -1.6517e-03, -2.8601e-02, -4.3967e-05]]],\n",
      "\n",
      "\n",
      "        [[[-9.4101e-03, -7.5338e-03, -1.5500e-02,  1.4375e-03,  3.9572e-02],\n",
      "          [ 4.2318e-02,  4.4539e-02,  6.2118e-03, -3.9396e-03,  2.4682e-03],\n",
      "          [ 1.6726e-02,  2.3747e-02, -4.1472e-03, -3.3103e-02,  2.3087e-02],\n",
      "          [ 1.9893e-02, -3.1072e-04,  3.4924e-02, -1.3472e-02,  2.4914e-02],\n",
      "          [ 1.9027e-02,  1.9569e-02, -1.3789e-02, -3.7984e-02, -3.1045e-03]]]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       requires_grad=True))\n",
      "('features.6.conv.4.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.6.conv.4.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.6.conv.5.fc.0.weight', Parameter containing:\n",
      "tensor([[ 5.9665e-03, -3.8021e-03,  3.5421e-03,  ..., -3.6672e-03,\n",
      "          7.4874e-03, -1.3496e-02],\n",
      "        [-1.2432e-02, -8.5493e-03, -5.1643e-03,  ..., -1.2559e-02,\n",
      "          1.4367e-06,  1.7496e-02],\n",
      "        [ 6.2288e-03, -1.6547e-02,  2.3937e-04,  ...,  4.2437e-03,\n",
      "          4.6887e-03, -1.9478e-02],\n",
      "        ...,\n",
      "        [-8.9740e-04,  2.2597e-03,  1.0211e-02,  ...,  4.6156e-03,\n",
      "         -6.7574e-03, -2.2072e-03],\n",
      "        [-1.3729e-02,  5.4880e-03, -2.1026e-02,  ...,  6.4599e-03,\n",
      "          1.6316e-02, -6.6359e-04],\n",
      "        [ 1.1281e-02, -9.1619e-03, -1.9215e-02,  ..., -1.2580e-02,\n",
      "          1.3473e-02,  3.8158e-03]], requires_grad=True))\n",
      "('features.6.conv.5.fc.2.weight', Parameter containing:\n",
      "tensor([[-3.9044e-03,  1.1199e-02,  2.5180e-03,  ..., -1.3339e-02,\n",
      "         -1.0802e-03,  4.9071e-03],\n",
      "        [ 4.3684e-03, -9.5202e-03,  7.1262e-03,  ..., -8.4571e-03,\n",
      "          1.3578e-03, -1.3272e-04],\n",
      "        [-3.1491e-03,  2.3493e-03,  7.5314e-03,  ...,  2.2107e-03,\n",
      "          5.1145e-04, -7.0546e-03],\n",
      "        ...,\n",
      "        [-5.7093e-03,  1.6778e-02, -3.6092e-02,  ...,  2.1536e-02,\n",
      "         -5.8223e-05, -1.0356e-03],\n",
      "        [ 5.6746e-03,  2.1160e-02,  2.6110e-03,  ..., -1.1451e-03,\n",
      "         -8.2519e-03, -1.7053e-02],\n",
      "        [ 1.6569e-02, -1.5313e-02, -1.8231e-04,  ..., -1.2258e-02,\n",
      "         -1.4773e-02,  1.6225e-02]], requires_grad=True))\n",
      "('features.6.conv.7.weight', Parameter containing:\n",
      "tensor([[[[-0.2760]],\n",
      "\n",
      "         [[ 0.1795]],\n",
      "\n",
      "         [[-0.1963]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0842]],\n",
      "\n",
      "         [[ 0.1543]],\n",
      "\n",
      "         [[-0.2081]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0382]],\n",
      "\n",
      "         [[-0.1759]],\n",
      "\n",
      "         [[-0.1641]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0020]],\n",
      "\n",
      "         [[-0.1290]],\n",
      "\n",
      "         [[-0.2659]]],\n",
      "\n",
      "\n",
      "        [[[-0.2157]],\n",
      "\n",
      "         [[-0.2174]],\n",
      "\n",
      "         [[-0.0147]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1421]],\n",
      "\n",
      "         [[ 0.1708]],\n",
      "\n",
      "         [[ 0.0935]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1073]],\n",
      "\n",
      "         [[ 0.0307]],\n",
      "\n",
      "         [[ 0.0421]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3046]],\n",
      "\n",
      "         [[-0.0038]],\n",
      "\n",
      "         [[-0.1706]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3249]],\n",
      "\n",
      "         [[-0.1503]],\n",
      "\n",
      "         [[ 0.3650]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0168]],\n",
      "\n",
      "         [[ 0.3699]],\n",
      "\n",
      "         [[-0.3721]]],\n",
      "\n",
      "\n",
      "        [[[-0.2836]],\n",
      "\n",
      "         [[ 0.1559]],\n",
      "\n",
      "         [[ 0.1103]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2557]],\n",
      "\n",
      "         [[-0.0337]],\n",
      "\n",
      "         [[-0.3327]]]], requires_grad=True))\n",
      "('features.6.conv.8.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1.], requires_grad=True))\n",
      "('features.6.conv.8.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.7.conv.0.weight', Parameter containing:\n",
      "tensor([[[[-0.0637]],\n",
      "\n",
      "         [[ 0.0866]],\n",
      "\n",
      "         [[ 0.1926]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0561]],\n",
      "\n",
      "         [[-0.3587]],\n",
      "\n",
      "         [[ 0.0587]]],\n",
      "\n",
      "\n",
      "        [[[-0.2262]],\n",
      "\n",
      "         [[-0.0772]],\n",
      "\n",
      "         [[ 0.2352]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0523]],\n",
      "\n",
      "         [[ 0.0915]],\n",
      "\n",
      "         [[-0.2748]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0625]],\n",
      "\n",
      "         [[-0.1791]],\n",
      "\n",
      "         [[ 0.0804]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0607]],\n",
      "\n",
      "         [[ 0.1222]],\n",
      "\n",
      "         [[ 0.0632]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0309]],\n",
      "\n",
      "         [[-0.1864]],\n",
      "\n",
      "         [[ 0.1171]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1161]],\n",
      "\n",
      "         [[ 0.1795]],\n",
      "\n",
      "         [[ 0.2172]]],\n",
      "\n",
      "\n",
      "        [[[-0.1051]],\n",
      "\n",
      "         [[-0.0641]],\n",
      "\n",
      "         [[ 0.1905]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1663]],\n",
      "\n",
      "         [[ 0.1544]],\n",
      "\n",
      "         [[-0.0974]]],\n",
      "\n",
      "\n",
      "        [[[-0.0361]],\n",
      "\n",
      "         [[ 0.0088]],\n",
      "\n",
      "         [[-0.1101]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0937]],\n",
      "\n",
      "         [[ 0.0346]],\n",
      "\n",
      "         [[ 0.1302]]]], requires_grad=True))\n",
      "('features.7.conv.1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.7.conv.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.7.conv.3.weight', Parameter containing:\n",
      "tensor([[[[ 2.9231e-02, -5.0559e-03, -7.3949e-03,  3.0833e-02,  6.2343e-03],\n",
      "          [ 1.9299e-02, -3.2110e-02, -1.3876e-02, -4.7021e-02, -2.7681e-02],\n",
      "          [ 4.7301e-02, -5.5747e-03, -3.6487e-02,  6.3152e-03,  1.4579e-02],\n",
      "          [ 1.2035e-02,  9.8327e-03, -1.0418e-02,  2.3234e-02,  1.3276e-02],\n",
      "          [ 1.4634e-02, -3.0320e-02,  2.1364e-02, -3.4927e-02, -3.0563e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2983e-02, -6.7332e-02, -1.6871e-03, -3.6656e-02, -3.0711e-02],\n",
      "          [-3.9164e-03,  2.5918e-02, -2.7377e-02,  1.9300e-02,  1.2679e-02],\n",
      "          [ 2.8483e-03, -2.4029e-02, -5.6077e-03, -3.5002e-02, -3.9249e-02],\n",
      "          [-2.2799e-02,  8.4214e-03, -2.0416e-02, -4.9698e-03,  8.2768e-03],\n",
      "          [-9.0548e-03, -7.2841e-04,  2.9303e-02,  7.1375e-03, -7.7437e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5881e-02, -1.0440e-03, -1.7380e-02, -1.3987e-02, -1.7915e-02],\n",
      "          [-3.4168e-02, -4.4085e-02, -4.9100e-03, -3.4239e-02, -2.3282e-02],\n",
      "          [ 2.0627e-02,  8.7877e-04,  5.4323e-02,  9.6798e-05,  4.0501e-02],\n",
      "          [-4.3272e-02,  5.0606e-03, -5.9654e-02,  8.6689e-02,  3.4517e-02],\n",
      "          [-1.9251e-02, -9.3597e-03,  6.0000e-03, -1.1327e-02,  3.5582e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.1406e-03,  2.1123e-02, -3.9134e-02, -1.2455e-02, -2.0076e-04],\n",
      "          [-3.0933e-02,  1.7600e-02,  2.6027e-02, -3.7508e-03,  1.0839e-02],\n",
      "          [-2.0974e-02, -4.5305e-03, -2.4449e-02,  1.3384e-02, -4.8569e-04],\n",
      "          [-1.3262e-02,  2.4139e-03,  1.3713e-02,  1.8297e-02,  2.0463e-02],\n",
      "          [ 9.2725e-03, -4.0237e-02,  4.7345e-03, -4.5352e-03,  7.4883e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.0981e-03,  2.0402e-02,  2.6307e-02,  4.4395e-02,  3.4473e-04],\n",
      "          [-1.7571e-02,  7.8690e-03,  3.2083e-03, -3.4321e-03, -1.7565e-02],\n",
      "          [ 2.5544e-03, -1.1445e-02, -1.6710e-02,  2.6039e-03, -1.5659e-02],\n",
      "          [ 7.0592e-02, -1.4895e-02,  4.4191e-02,  1.1422e-02, -3.0380e-02],\n",
      "          [-2.1304e-02, -6.0644e-05, -2.0487e-02,  3.6459e-02,  2.9050e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3839e-02,  1.1474e-02,  3.5901e-02, -9.9819e-03,  3.2659e-03],\n",
      "          [-2.9954e-03, -2.0595e-02,  1.1084e-02,  1.2739e-02,  1.7317e-02],\n",
      "          [ 1.3866e-02, -3.1262e-02,  3.7251e-02, -4.1151e-02,  1.1231e-02],\n",
      "          [ 1.0659e-02, -2.4899e-02,  4.2108e-02,  6.4520e-03, -2.1679e-02],\n",
      "          [-2.4415e-02,  8.0647e-02, -1.1521e-02,  1.9006e-02,  5.2512e-02]]]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       requires_grad=True))\n",
      "('features.7.conv.4.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.7.conv.4.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.7.conv.5.fc.0.weight', Parameter containing:\n",
      "tensor([[-0.0110,  0.0011,  0.0020,  ...,  0.0149, -0.0039, -0.0125],\n",
      "        [-0.0009, -0.0062, -0.0042,  ..., -0.0121,  0.0002, -0.0066],\n",
      "        [ 0.0006, -0.0052,  0.0069,  ..., -0.0120, -0.0014, -0.0210],\n",
      "        ...,\n",
      "        [ 0.0069, -0.0012,  0.0182,  ..., -0.0012,  0.0009, -0.0072],\n",
      "        [-0.0051,  0.0021, -0.0190,  ...,  0.0224, -0.0161,  0.0073],\n",
      "        [-0.0046, -0.0110, -0.0053,  ...,  0.0081,  0.0014, -0.0055]],\n",
      "       requires_grad=True))\n",
      "('features.7.conv.5.fc.2.weight', Parameter containing:\n",
      "tensor([[-0.0056,  0.0078,  0.0135,  ...,  0.0172, -0.0038, -0.0036],\n",
      "        [ 0.0027,  0.0205,  0.0011,  ...,  0.0104, -0.0077,  0.0070],\n",
      "        [-0.0039, -0.0007,  0.0058,  ...,  0.0122, -0.0066, -0.0095],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0054,  0.0064,  ..., -0.0152, -0.0101, -0.0101],\n",
      "        [ 0.0062, -0.0036, -0.0170,  ...,  0.0063, -0.0046, -0.0038],\n",
      "        [ 0.0081,  0.0135,  0.0003,  ...,  0.0097, -0.0113,  0.0028]],\n",
      "       requires_grad=True))\n",
      "('features.7.conv.7.weight', Parameter containing:\n",
      "tensor([[[[ 0.0972]],\n",
      "\n",
      "         [[-0.1116]],\n",
      "\n",
      "         [[ 0.0904]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0414]],\n",
      "\n",
      "         [[-0.1958]],\n",
      "\n",
      "         [[ 0.2959]]],\n",
      "\n",
      "\n",
      "        [[[-0.2670]],\n",
      "\n",
      "         [[ 0.0246]],\n",
      "\n",
      "         [[-0.2618]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3697]],\n",
      "\n",
      "         [[ 0.2492]],\n",
      "\n",
      "         [[ 0.2756]]],\n",
      "\n",
      "\n",
      "        [[[-0.2411]],\n",
      "\n",
      "         [[ 0.1040]],\n",
      "\n",
      "         [[ 0.1521]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5384]],\n",
      "\n",
      "         [[ 0.1091]],\n",
      "\n",
      "         [[-0.2982]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1265]],\n",
      "\n",
      "         [[ 0.0847]],\n",
      "\n",
      "         [[ 0.2851]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0312]],\n",
      "\n",
      "         [[-0.0632]],\n",
      "\n",
      "         [[-0.2520]]],\n",
      "\n",
      "\n",
      "        [[[-0.0305]],\n",
      "\n",
      "         [[ 0.0285]],\n",
      "\n",
      "         [[ 0.2722]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1450]],\n",
      "\n",
      "         [[ 0.0372]],\n",
      "\n",
      "         [[ 0.0236]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2051]],\n",
      "\n",
      "         [[-0.2306]],\n",
      "\n",
      "         [[ 0.1105]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0345]],\n",
      "\n",
      "         [[-0.0999]],\n",
      "\n",
      "         [[ 0.2645]]]], requires_grad=True))\n",
      "('features.7.conv.8.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.7.conv.8.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.8.conv.0.weight', Parameter containing:\n",
      "tensor([[[[ 0.1116]],\n",
      "\n",
      "         [[-0.0459]],\n",
      "\n",
      "         [[ 0.0718]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1228]],\n",
      "\n",
      "         [[-0.1273]],\n",
      "\n",
      "         [[ 0.0169]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1601]],\n",
      "\n",
      "         [[-0.0055]],\n",
      "\n",
      "         [[ 0.0819]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0026]],\n",
      "\n",
      "         [[-0.1198]],\n",
      "\n",
      "         [[-0.0382]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1032]],\n",
      "\n",
      "         [[ 0.0145]],\n",
      "\n",
      "         [[-0.1516]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0354]],\n",
      "\n",
      "         [[-0.0673]],\n",
      "\n",
      "         [[-0.1278]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0778]],\n",
      "\n",
      "         [[ 0.0007]],\n",
      "\n",
      "         [[ 0.2044]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0935]],\n",
      "\n",
      "         [[ 0.0381]],\n",
      "\n",
      "         [[ 0.0834]]],\n",
      "\n",
      "\n",
      "        [[[-0.3691]],\n",
      "\n",
      "         [[ 0.0141]],\n",
      "\n",
      "         [[-0.0226]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1551]],\n",
      "\n",
      "         [[-0.0464]],\n",
      "\n",
      "         [[ 0.0297]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1001]],\n",
      "\n",
      "         [[-0.0100]],\n",
      "\n",
      "         [[-0.1415]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1068]],\n",
      "\n",
      "         [[ 0.0925]],\n",
      "\n",
      "         [[ 0.0520]]]], requires_grad=True))\n",
      "('features.8.conv.1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.8.conv.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.8.conv.3.weight', Parameter containing:\n",
      "tensor([[[[ 0.0076, -0.0019,  0.0126,  0.0099, -0.0433],\n",
      "          [-0.0129,  0.0143,  0.0055, -0.0127, -0.0226],\n",
      "          [ 0.0033, -0.0227, -0.0130,  0.0006,  0.0213],\n",
      "          [ 0.0270, -0.0595,  0.0188, -0.0127,  0.0382],\n",
      "          [-0.0028, -0.0135,  0.0028,  0.0579,  0.0180]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0046, -0.0412,  0.0510, -0.0133, -0.0158],\n",
      "          [-0.0008,  0.0179,  0.0380,  0.0186, -0.0579],\n",
      "          [-0.0229, -0.0016, -0.0344,  0.0245,  0.0274],\n",
      "          [ 0.0267, -0.0381, -0.0317,  0.0222,  0.0208],\n",
      "          [-0.0033,  0.0326, -0.0312, -0.0093,  0.0096]]],\n",
      "\n",
      "\n",
      "        [[[-0.0018, -0.0097,  0.0308,  0.0068,  0.0379],\n",
      "          [ 0.0466,  0.0420, -0.0091, -0.0346,  0.0111],\n",
      "          [-0.0224,  0.0261,  0.0104, -0.0029,  0.0094],\n",
      "          [ 0.0200,  0.0219, -0.0325,  0.0137, -0.0448],\n",
      "          [ 0.0253,  0.0081, -0.0073, -0.0263, -0.0285]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0225,  0.0264,  0.0223, -0.0189, -0.0105],\n",
      "          [-0.0361, -0.0044, -0.0291,  0.0219, -0.0201],\n",
      "          [-0.0103,  0.0413, -0.0090, -0.0074,  0.0060],\n",
      "          [-0.0111,  0.0090,  0.0235, -0.0211,  0.0039],\n",
      "          [-0.0007, -0.0035,  0.0290, -0.0168,  0.0210]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0144,  0.0307, -0.0396, -0.0160,  0.0018],\n",
      "          [ 0.0027, -0.0213, -0.0054, -0.0074, -0.0294],\n",
      "          [-0.0392,  0.0012,  0.0090, -0.0065, -0.0158],\n",
      "          [-0.0141,  0.0171, -0.0078, -0.0525,  0.0175],\n",
      "          [-0.0047, -0.0293, -0.0168,  0.0151,  0.0074]]],\n",
      "\n",
      "\n",
      "        [[[-0.0129, -0.0111,  0.0107, -0.0009,  0.0056],\n",
      "          [ 0.0139, -0.0177, -0.0136,  0.0115, -0.0141],\n",
      "          [ 0.0094, -0.0082,  0.0015, -0.0441, -0.0571],\n",
      "          [-0.0004,  0.0069, -0.0111, -0.0028, -0.0028],\n",
      "          [-0.0189,  0.0482,  0.0184, -0.0328, -0.0035]]]], requires_grad=True))\n",
      "('features.8.conv.4.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       requires_grad=True))\n",
      "('features.8.conv.4.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.8.conv.5.fc.0.weight', Parameter containing:\n",
      "tensor([[ 0.0021, -0.0014,  0.0050,  ...,  0.0076, -0.0216, -0.0016],\n",
      "        [ 0.0057, -0.0011,  0.0029,  ..., -0.0119,  0.0092, -0.0073],\n",
      "        [-0.0174, -0.0128, -0.0013,  ...,  0.0019, -0.0083,  0.0069],\n",
      "        ...,\n",
      "        [ 0.0077, -0.0050, -0.0050,  ..., -0.0051,  0.0070,  0.0079],\n",
      "        [-0.0119, -0.0147,  0.0037,  ..., -0.0008, -0.0034, -0.0075],\n",
      "        [ 0.0059, -0.0151, -0.0057,  ..., -0.0013, -0.0042,  0.0083]],\n",
      "       requires_grad=True))\n",
      "('features.8.conv.5.fc.2.weight', Parameter containing:\n",
      "tensor([[-0.0017, -0.0171,  0.0060,  ..., -0.0080,  0.0148,  0.0124],\n",
      "        [ 0.0012, -0.0064, -0.0109,  ...,  0.0037,  0.0050,  0.0050],\n",
      "        [-0.0018,  0.0134, -0.0006,  ...,  0.0032,  0.0062,  0.0142],\n",
      "        ...,\n",
      "        [-0.0142, -0.0084, -0.0095,  ...,  0.0041, -0.0056, -0.0014],\n",
      "        [-0.0087,  0.0180, -0.0046,  ..., -0.0028,  0.0066,  0.0011],\n",
      "        [-0.0063, -0.0033, -0.0162,  ...,  0.0063,  0.0048, -0.0054]],\n",
      "       requires_grad=True))\n",
      "('features.8.conv.7.weight', Parameter containing:\n",
      "tensor([[[[ 0.2659]],\n",
      "\n",
      "         [[ 0.2678]],\n",
      "\n",
      "         [[ 0.3263]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2820]],\n",
      "\n",
      "         [[-0.3152]],\n",
      "\n",
      "         [[-0.0130]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0028]],\n",
      "\n",
      "         [[-0.0700]],\n",
      "\n",
      "         [[ 0.3422]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2171]],\n",
      "\n",
      "         [[ 0.1843]],\n",
      "\n",
      "         [[ 0.4977]]],\n",
      "\n",
      "\n",
      "        [[[-0.3235]],\n",
      "\n",
      "         [[-0.1404]],\n",
      "\n",
      "         [[-0.2709]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0663]],\n",
      "\n",
      "         [[-0.0288]],\n",
      "\n",
      "         [[-0.2094]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.3046]],\n",
      "\n",
      "         [[-0.0812]],\n",
      "\n",
      "         [[-0.2126]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0216]],\n",
      "\n",
      "         [[-0.1060]],\n",
      "\n",
      "         [[ 0.0591]]],\n",
      "\n",
      "\n",
      "        [[[-0.4434]],\n",
      "\n",
      "         [[ 0.3311]],\n",
      "\n",
      "         [[ 0.0180]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0293]],\n",
      "\n",
      "         [[-0.1455]],\n",
      "\n",
      "         [[-0.3212]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0265]],\n",
      "\n",
      "         [[ 0.5741]],\n",
      "\n",
      "         [[ 0.1434]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0062]],\n",
      "\n",
      "         [[-0.4378]],\n",
      "\n",
      "         [[-0.3334]]]], requires_grad=True))\n",
      "('features.8.conv.8.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.8.conv.8.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.9.conv.0.weight', Parameter containing:\n",
      "tensor([[[[-0.0726]],\n",
      "\n",
      "         [[-0.0207]],\n",
      "\n",
      "         [[ 0.0926]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0152]],\n",
      "\n",
      "         [[ 0.0731]],\n",
      "\n",
      "         [[-0.0196]]],\n",
      "\n",
      "\n",
      "        [[[-0.0877]],\n",
      "\n",
      "         [[ 0.0313]],\n",
      "\n",
      "         [[ 0.0793]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0289]],\n",
      "\n",
      "         [[ 0.1767]],\n",
      "\n",
      "         [[-0.0475]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0212]],\n",
      "\n",
      "         [[-0.0174]],\n",
      "\n",
      "         [[-0.0014]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0344]],\n",
      "\n",
      "         [[ 0.0944]],\n",
      "\n",
      "         [[-0.0529]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1089]],\n",
      "\n",
      "         [[-0.1132]],\n",
      "\n",
      "         [[-0.0102]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0128]],\n",
      "\n",
      "         [[-0.0446]],\n",
      "\n",
      "         [[-0.0433]]],\n",
      "\n",
      "\n",
      "        [[[-0.0361]],\n",
      "\n",
      "         [[-0.0772]],\n",
      "\n",
      "         [[-0.0362]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0206]],\n",
      "\n",
      "         [[ 0.0461]],\n",
      "\n",
      "         [[-0.0757]]],\n",
      "\n",
      "\n",
      "        [[[-0.0671]],\n",
      "\n",
      "         [[ 0.1025]],\n",
      "\n",
      "         [[-0.0455]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0028]],\n",
      "\n",
      "         [[-0.0518]],\n",
      "\n",
      "         [[-0.1187]]]], requires_grad=True))\n",
      "('features.9.conv.1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.9.conv.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.9.conv.3.weight', Parameter containing:\n",
      "tensor([[[[-0.0323, -0.0086, -0.0215,  0.0051, -0.0203],\n",
      "          [-0.0181, -0.0012, -0.0096, -0.0145, -0.0172],\n",
      "          [ 0.0104, -0.0018, -0.0124,  0.0045,  0.0004],\n",
      "          [-0.0109,  0.0102,  0.0134, -0.0187,  0.0237],\n",
      "          [-0.0022, -0.0191, -0.0299, -0.0036, -0.0039]]],\n",
      "\n",
      "\n",
      "        [[[-0.0033, -0.0058,  0.0077, -0.0125, -0.0079],\n",
      "          [-0.0282, -0.0196, -0.0205, -0.0073, -0.0176],\n",
      "          [ 0.0067,  0.0172,  0.0259, -0.0021,  0.0111],\n",
      "          [-0.0185, -0.0137,  0.0003,  0.0395,  0.0069],\n",
      "          [ 0.0055,  0.0118, -0.0036,  0.0115, -0.0046]]],\n",
      "\n",
      "\n",
      "        [[[-0.0032, -0.0138,  0.0205, -0.0224,  0.0149],\n",
      "          [ 0.0215,  0.0195, -0.0072, -0.0180,  0.0062],\n",
      "          [-0.0153, -0.0174,  0.0115,  0.0077, -0.0357],\n",
      "          [ 0.0080,  0.0089,  0.0217, -0.0034, -0.0073],\n",
      "          [-0.0010, -0.0044,  0.0011,  0.0079,  0.0404]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0093,  0.0051, -0.0037, -0.0149, -0.0079],\n",
      "          [-0.0164, -0.0252,  0.0136,  0.0051, -0.0150],\n",
      "          [ 0.0093,  0.0122, -0.0151,  0.0120, -0.0151],\n",
      "          [ 0.0108, -0.0227, -0.0006, -0.0260,  0.0070],\n",
      "          [-0.0163,  0.0045, -0.0118, -0.0312,  0.0168]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0206, -0.0030,  0.0298,  0.0070, -0.0051],\n",
      "          [-0.0007,  0.0052, -0.0224,  0.0121, -0.0045],\n",
      "          [-0.0073, -0.0237, -0.0057, -0.0262, -0.0029],\n",
      "          [-0.0023,  0.0104,  0.0175,  0.0395, -0.0021],\n",
      "          [-0.0015,  0.0271,  0.0100, -0.0003,  0.0112]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0281, -0.0047, -0.0233, -0.0107,  0.0333],\n",
      "          [-0.0290,  0.0209, -0.0295,  0.0215,  0.0189],\n",
      "          [ 0.0063, -0.0118,  0.0211,  0.0343, -0.0247],\n",
      "          [ 0.0176, -0.0109, -0.0348, -0.0038,  0.0124],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [ 0.0095, -0.0070, -0.0153, -0.0068, -0.0019]]]], requires_grad=True))\n",
      "('features.9.conv.4.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.9.conv.4.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.9.conv.5.fc.0.weight', Parameter containing:\n",
      "tensor([[-0.0246,  0.0085,  0.0005,  ..., -0.0057,  0.0007,  0.0106],\n",
      "        [-0.0052, -0.0026,  0.0164,  ...,  0.0117,  0.0168, -0.0047],\n",
      "        [ 0.0164,  0.0092,  0.0164,  ..., -0.0109,  0.0004, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0028, -0.0016,  0.0119,  ...,  0.0166, -0.0018,  0.0145],\n",
      "        [-0.0076, -0.0018,  0.0138,  ..., -0.0193, -0.0104,  0.0014],\n",
      "        [-0.0058, -0.0021,  0.0007,  ...,  0.0146,  0.0075, -0.0157]],\n",
      "       requires_grad=True))\n",
      "('features.9.conv.5.fc.2.weight', Parameter containing:\n",
      "tensor([[-0.0039,  0.0017,  0.0005,  ..., -0.0023,  0.0156,  0.0108],\n",
      "        [ 0.0015,  0.0124, -0.0113,  ...,  0.0008, -0.0230, -0.0040],\n",
      "        [ 0.0085,  0.0014,  0.0123,  ...,  0.0044,  0.0016, -0.0003],\n",
      "        ...,\n",
      "        [-0.0055, -0.0008,  0.0011,  ...,  0.0009, -0.0001, -0.0011],\n",
      "        [-0.0113,  0.0183, -0.0127,  ..., -0.0002, -0.0023,  0.0066],\n",
      "        [ 0.0126, -0.0136,  0.0013,  ...,  0.0053,  0.0116,  0.0041]],\n",
      "       requires_grad=True))\n",
      "('features.9.conv.7.weight', Parameter containing:\n",
      "tensor([[[[-0.1200]],\n",
      "\n",
      "         [[ 0.0429]],\n",
      "\n",
      "         [[ 0.0381]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0545]],\n",
      "\n",
      "         [[ 0.0930]],\n",
      "\n",
      "         [[-0.0693]]],\n",
      "\n",
      "\n",
      "        [[[-0.0096]],\n",
      "\n",
      "         [[-0.1587]],\n",
      "\n",
      "         [[ 0.0150]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0037]],\n",
      "\n",
      "         [[ 0.1103]],\n",
      "\n",
      "         [[-0.0795]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1940]],\n",
      "\n",
      "         [[ 0.2538]],\n",
      "\n",
      "         [[ 0.0598]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1209]],\n",
      "\n",
      "         [[-0.1954]],\n",
      "\n",
      "         [[-0.0192]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1849]],\n",
      "\n",
      "         [[-0.0337]],\n",
      "\n",
      "         [[-0.0403]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1369]],\n",
      "\n",
      "         [[-0.0042]],\n",
      "\n",
      "         [[-0.1150]]],\n",
      "\n",
      "\n",
      "        [[[-0.1260]],\n",
      "\n",
      "         [[ 0.1165]],\n",
      "\n",
      "         [[-0.1436]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0336]],\n",
      "\n",
      "         [[-0.0056]],\n",
      "\n",
      "         [[-0.0581]]],\n",
      "\n",
      "\n",
      "        [[[-0.0935]],\n",
      "\n",
      "         [[ 0.2422]],\n",
      "\n",
      "         [[ 0.0488]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0249]],\n",
      "\n",
      "         [[-0.0358]],\n",
      "\n",
      "         [[ 0.2648]]]], requires_grad=True))\n",
      "('features.9.conv.8.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.9.conv.8.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.10.conv.0.weight', Parameter containing:\n",
      "tensor([[[[ 0.0720]],\n",
      "\n",
      "         [[ 0.0408]],\n",
      "\n",
      "         [[ 0.0103]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0326]],\n",
      "\n",
      "         [[ 0.0927]],\n",
      "\n",
      "         [[ 0.0495]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0165]],\n",
      "\n",
      "         [[-0.0233]],\n",
      "\n",
      "         [[ 0.0647]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0401]],\n",
      "\n",
      "         [[ 0.0499]],\n",
      "\n",
      "         [[-0.0466]]],\n",
      "\n",
      "\n",
      "        [[[-0.0676]],\n",
      "\n",
      "         [[ 0.0375]],\n",
      "\n",
      "         [[-0.0799]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0566]],\n",
      "\n",
      "         [[ 0.0515]],\n",
      "\n",
      "         [[ 0.0443]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0144]],\n",
      "\n",
      "         [[-0.0945]],\n",
      "\n",
      "         [[ 0.0205]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0448]],\n",
      "\n",
      "         [[ 0.0411]],\n",
      "\n",
      "         [[ 0.0561]]],\n",
      "\n",
      "\n",
      "        [[[-0.0944]],\n",
      "\n",
      "         [[ 0.0525]],\n",
      "\n",
      "         [[ 0.0345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0407]],\n",
      "\n",
      "         [[ 0.0331]],\n",
      "\n",
      "         [[-0.0618]]],\n",
      "\n",
      "\n",
      "        [[[-0.0061]],\n",
      "\n",
      "         [[-0.0631]],\n",
      "\n",
      "         [[ 0.0943]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0259]],\n",
      "\n",
      "         [[-0.0503]],\n",
      "\n",
      "         [[ 0.0002]]]], requires_grad=True))\n",
      "('features.10.conv.1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       requires_grad=True))\n",
      "('features.10.conv.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.10.conv.3.weight', Parameter containing:\n",
      "tensor([[[[ 2.8927e-02,  1.7461e-02, -9.5046e-03, -1.6302e-02, -8.2105e-04],\n",
      "          [ 1.0463e-02,  1.3113e-02, -4.6207e-03, -1.1308e-02, -1.0748e-02],\n",
      "          [-1.4363e-02, -1.5587e-02, -5.8087e-03,  2.5628e-02,  6.1050e-03],\n",
      "          [ 4.6486e-02,  7.4132e-03,  2.6071e-02,  1.6246e-03, -8.1645e-03],\n",
      "          [-3.1797e-03,  1.8609e-02, -5.5899e-03, -5.1034e-03, -1.5213e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.8443e-03,  4.3802e-03, -3.1297e-02,  1.7610e-03,  1.8482e-02],\n",
      "          [-4.6503e-03, -1.8797e-02,  4.5058e-03,  4.1313e-03,  5.6365e-03],\n",
      "          [ 5.5766e-03, -3.4454e-03, -1.5563e-02,  7.0555e-03, -1.3907e-03],\n",
      "          [-1.1767e-02,  5.8908e-03,  1.6603e-02,  6.7934e-03,  3.4043e-03],\n",
      "          [-2.9895e-04,  1.1214e-03,  7.9442e-03, -1.1000e-02, -2.1293e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.5428e-02,  1.1297e-03, -2.0473e-02,  1.4576e-02,  1.4872e-02],\n",
      "          [-1.2957e-02, -4.6422e-04, -1.3644e-02, -5.1089e-03, -4.2929e-03],\n",
      "          [ 7.1228e-03,  1.3372e-02, -2.5801e-03,  3.1003e-02,  2.3178e-03],\n",
      "          [-2.0969e-02,  1.8709e-02, -4.2940e-03, -2.1590e-03, -2.0496e-03],\n",
      "          [-3.1222e-02,  1.0316e-02,  4.3066e-03, -8.7133e-04, -1.7327e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.3143e-02, -8.2346e-03, -1.5462e-02,  2.8831e-03,  1.0129e-02],\n",
      "          [-3.2530e-03, -6.6437e-03,  9.7015e-03,  1.3657e-02, -4.3658e-03],\n",
      "          [-1.3976e-02, -8.4788e-04, -9.2415e-03, -9.0612e-03,  3.8788e-03],\n",
      "          [-2.6056e-05, -2.1943e-02, -1.0918e-02, -9.6264e-03,  2.5487e-03],\n",
      "          [ 1.1922e-02,  1.4961e-02, -7.9819e-03,  1.6056e-02, -1.1286e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0807e-02,  4.9892e-03, -9.0880e-03, -6.9177e-03, -1.6912e-02],\n",
      "          [-1.7879e-02,  4.7648e-03,  5.1502e-03, -1.1177e-03,  3.8303e-03],\n",
      "          [-1.3367e-03, -1.8352e-02,  1.4559e-05,  5.0852e-03,  2.9603e-02],\n",
      "          [ 1.1584e-02,  5.2877e-03, -1.1642e-02, -1.2587e-02, -1.0699e-02],\n",
      "          [-1.8500e-02,  1.0837e-02,  9.0045e-03,  8.6429e-03,  5.0305e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2945e-04,  5.9906e-04,  1.1158e-02,  1.6340e-02, -1.0934e-02],\n",
      "          [ 1.8357e-02,  2.4950e-02, -1.4479e-02, -1.3673e-02, -1.1047e-02],\n",
      "          [-1.2979e-03, -1.1906e-02, -1.6018e-03,  1.4887e-02, -8.2051e-03],\n",
      "          [ 4.5443e-03,  6.9151e-03, -1.2926e-02,  4.8858e-03,  3.9434e-03],\n",
      "          [ 1.0470e-02, -5.0196e-03, -6.7592e-03,  6.2975e-03,  2.4142e-02]]]],\n",
      "       requires_grad=True))\n",
      "('features.10.conv.4.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.10.conv.4.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       requires_grad=True))\n",
      "('features.10.conv.5.fc.0.weight', Parameter containing:\n",
      "tensor([[-0.0033,  0.0068,  0.0080,  ..., -0.0083, -0.0051, -0.0137],\n",
      "        [-0.0089, -0.0061, -0.0009,  ..., -0.0016, -0.0120,  0.0049],\n",
      "        [-0.0093, -0.0148, -0.0228,  ..., -0.0085, -0.0043,  0.0067],\n",
      "        ...,\n",
      "        [ 0.0019,  0.0071, -0.0141,  ...,  0.0103,  0.0086, -0.0089],\n",
      "        [-0.0050,  0.0042, -0.0031,  ..., -0.0067,  0.0036, -0.0093],\n",
      "        [-0.0095, -0.0068, -0.0148,  ...,  0.0055,  0.0085,  0.0119]],\n",
      "       requires_grad=True))\n",
      "('features.10.conv.5.fc.2.weight', Parameter containing:\n",
      "tensor([[ 1.6070e-02, -4.8493e-03,  1.6137e-03,  ..., -9.3481e-03,\n",
      "         -2.6021e-03,  9.1733e-03],\n",
      "        [-2.3350e-02,  6.9596e-03, -1.7006e-03,  ...,  1.2949e-02,\n",
      "         -9.6765e-03, -8.9649e-03],\n",
      "        [ 9.7184e-03,  4.3505e-03,  3.8711e-03,  ..., -1.1226e-03,\n",
      "          1.4709e-02, -9.4082e-03],\n",
      "        ...,\n",
      "        [-4.1899e-04, -9.9561e-03,  2.2383e-03,  ...,  1.6828e-02,\n",
      "         -7.3575e-03,  2.3763e-03],\n",
      "        [-5.8577e-03,  6.5659e-05,  1.8540e-03,  ...,  7.2984e-03,\n",
      "         -1.0864e-03, -1.6970e-02],\n",
      "        [ 1.4588e-02,  1.4192e-03,  1.0386e-03,  ...,  8.0277e-03,\n",
      "          1.6177e-03, -8.3928e-03]], requires_grad=True))\n",
      "('features.10.conv.7.weight', Parameter containing:\n",
      "tensor([[[[ 0.1339]],\n",
      "\n",
      "         [[-0.1600]],\n",
      "\n",
      "         [[-0.1043]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0209]],\n",
      "\n",
      "         [[ 0.0466]],\n",
      "\n",
      "         [[-0.2064]]],\n",
      "\n",
      "\n",
      "        [[[-0.1294]],\n",
      "\n",
      "         [[ 0.0320]],\n",
      "\n",
      "         [[-0.0223]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1346]],\n",
      "\n",
      "         [[ 0.0255]],\n",
      "\n",
      "         [[-0.1590]]],\n",
      "\n",
      "\n",
      "        [[[-0.3809]],\n",
      "\n",
      "         [[-0.1069]],\n",
      "\n",
      "         [[-0.0627]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1492]],\n",
      "\n",
      "         [[-0.1051]],\n",
      "\n",
      "         [[-0.1326]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1300]],\n",
      "\n",
      "         [[ 0.0259]],\n",
      "\n",
      "         [[-0.0063]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1710]],\n",
      "\n",
      "         [[ 0.0740]],\n",
      "\n",
      "         [[ 0.0687]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0781]],\n",
      "\n",
      "         [[-0.0074]],\n",
      "\n",
      "         [[-0.0208]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0658]],\n",
      "\n",
      "         [[-0.0386]],\n",
      "\n",
      "         [[-0.1530]]],\n",
      "\n",
      "\n",
      "        [[[-0.2684]],\n",
      "\n",
      "         [[-0.0770]],\n",
      "\n",
      "         [[ 0.0070]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0905]],\n",
      "\n",
      "         [[ 0.1896]],\n",
      "\n",
      "         [[-0.1934]]]], requires_grad=True))\n",
      "('features.10.conv.8.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.10.conv.8.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.11.conv.0.weight', Parameter containing:\n",
      "tensor([[[[ 0.0163]],\n",
      "\n",
      "         [[-0.0147]],\n",
      "\n",
      "         [[-0.0087]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0085]],\n",
      "\n",
      "         [[ 0.0139]],\n",
      "\n",
      "         [[-0.0153]]],\n",
      "\n",
      "\n",
      "        [[[-0.0343]],\n",
      "\n",
      "         [[-0.0184]],\n",
      "\n",
      "         [[ 0.1666]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0220]],\n",
      "\n",
      "         [[ 0.0356]],\n",
      "\n",
      "         [[-0.0083]]],\n",
      "\n",
      "\n",
      "        [[[-0.0361]],\n",
      "\n",
      "         [[-0.0205]],\n",
      "\n",
      "         [[ 0.0096]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0833]],\n",
      "\n",
      "         [[ 0.0991]],\n",
      "\n",
      "         [[-0.0641]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0343]],\n",
      "\n",
      "         [[-0.0926]],\n",
      "\n",
      "         [[-0.0759]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0479]],\n",
      "\n",
      "         [[ 0.0729]],\n",
      "\n",
      "         [[-0.1083]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0313]],\n",
      "\n",
      "         [[ 0.0687]],\n",
      "\n",
      "         [[-0.0697]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0415]],\n",
      "\n",
      "         [[ 0.0318]],\n",
      "\n",
      "         [[ 0.0249]]],\n",
      "\n",
      "\n",
      "        [[[-0.0193]],\n",
      "\n",
      "         [[ 0.0616]],\n",
      "\n",
      "         [[-0.0714]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0703]],\n",
      "\n",
      "         [[ 0.1047]],\n",
      "\n",
      "         [[-0.0152]]]], requires_grad=True))\n",
      "('features.11.conv.1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.11.conv.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       requires_grad=True))\n",
      "('features.11.conv.3.weight', Parameter containing:\n",
      "tensor([[[[-2.0490e-02,  1.5196e-02, -4.9326e-03, -1.6522e-03, -1.4019e-02],\n",
      "          [-7.6199e-03,  4.1207e-03, -7.0759e-03,  1.1320e-02,  1.3983e-02],\n",
      "          [-2.0495e-02, -9.0694e-03,  2.1807e-02, -3.0034e-03, -2.3948e-04],\n",
      "          [-3.7610e-06,  1.0979e-03, -6.2111e-03, -5.6571e-03, -9.2305e-03],\n",
      "          [-8.6383e-03,  1.0686e-02, -8.9096e-03, -1.3061e-02, -2.0410e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2328e-02,  1.6387e-04,  1.5624e-03, -7.9043e-03, -3.3251e-03],\n",
      "          [-3.9875e-03, -6.6285e-04, -5.2713e-03,  2.2458e-03, -4.3907e-04],\n",
      "          [ 6.5037e-03,  1.9969e-02,  3.7040e-04, -9.5742e-03, -1.4058e-02],\n",
      "          [-1.2536e-02,  9.2934e-03,  2.3671e-02,  4.9412e-03, -1.4155e-02],\n",
      "          [ 1.5455e-02,  1.2759e-03,  1.4110e-03,  1.6255e-02, -2.1020e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.5031e-04,  6.0331e-03,  1.0934e-02,  3.0287e-03, -2.5322e-03],\n",
      "          [-5.8618e-03, -2.6175e-03,  1.2523e-02,  4.0511e-03,  7.1252e-03],\n",
      "          [-5.3696e-03, -1.0868e-02,  1.5667e-02,  2.6912e-03,  5.8080e-03],\n",
      "          [ 1.5074e-02,  8.0990e-03,  1.4167e-02, -1.2764e-02, -5.6489e-03],\n",
      "          [-8.5765e-04,  3.2249e-03, -3.9752e-03,  2.5619e-05, -1.2644e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.2933e-04,  5.9044e-03, -1.0504e-02, -4.2063e-03, -1.2498e-02],\n",
      "          [ 7.7014e-03, -1.5144e-02, -3.9663e-03,  1.3358e-02, -1.4277e-02],\n",
      "          [ 1.5730e-02, -8.4049e-03,  8.4781e-03, -5.7652e-03,  2.8053e-03],\n",
      "          [-2.0023e-03, -5.4169e-03,  4.6114e-03,  1.1354e-02,  3.7973e-03],\n",
      "          [-7.5390e-03,  1.9811e-02,  8.4074e-03,  5.6049e-03,  1.7280e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0737e-02, -2.4695e-02, -1.0494e-02, -7.1587e-03, -1.4957e-03],\n",
      "          [-5.3614e-03, -2.8780e-03, -5.2564e-04,  2.0275e-02,  2.6672e-03],\n",
      "          [ 1.7303e-02,  3.2088e-03,  4.0548e-02, -1.0848e-02,  1.4897e-02],\n",
      "          [ 2.1707e-02,  2.2340e-02, -1.4858e-03, -1.4242e-02, -1.9837e-03],\n",
      "          [-8.2017e-03,  1.3444e-02, -9.3142e-03,  3.8169e-03,  3.0239e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.2017e-02,  4.3572e-03,  7.6004e-03, -5.4963e-03,  2.7646e-03],\n",
      "          [ 3.6258e-03,  2.8667e-04, -2.9380e-02,  1.3058e-03,  1.2865e-02],\n",
      "          [-1.0495e-03,  7.7585e-03, -9.9017e-03, -1.8473e-02, -9.5504e-03],\n",
      "          [-3.3196e-03, -1.0602e-02, -9.6267e-03,  2.2794e-02, -1.7466e-02],\n",
      "          [-7.4322e-03, -7.5130e-03, -3.4807e-03, -4.0839e-03,  3.1875e-03]]]],\n",
      "       requires_grad=True))\n",
      "('features.11.conv.4.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.11.conv.4.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.11.conv.5.fc.0.weight', Parameter containing:\n",
      "tensor([[ 0.0235,  0.0089,  0.0233,  ...,  0.0244,  0.0034,  0.0030],\n",
      "        [-0.0067,  0.0090,  0.0005,  ...,  0.0016, -0.0025,  0.0014],\n",
      "        [-0.0008,  0.0105,  0.0056,  ..., -0.0129, -0.0091, -0.0152],\n",
      "        ...,\n",
      "        [ 0.0136, -0.0062, -0.0164,  ..., -0.0047, -0.0056,  0.0022],\n",
      "        [-0.0149,  0.0082, -0.0226,  ...,  0.0071,  0.0042, -0.0122],\n",
      "        [ 0.0048,  0.0200, -0.0240,  ..., -0.0089,  0.0103, -0.0176]],\n",
      "       requires_grad=True))\n",
      "('features.11.conv.5.fc.2.weight', Parameter containing:\n",
      "tensor([[-0.0014, -0.0058, -0.0009,  ...,  0.0066,  0.0025,  0.0131],\n",
      "        [ 0.0064, -0.0150, -0.0146,  ...,  0.0011,  0.0030, -0.0064],\n",
      "        [ 0.0004,  0.0070,  0.0122,  ...,  0.0059, -0.0010, -0.0096],\n",
      "        ...,\n",
      "        [-0.0090,  0.0125,  0.0202,  ..., -0.0033, -0.0042,  0.0005],\n",
      "        [ 0.0083, -0.0017, -0.0011,  ...,  0.0020,  0.0089, -0.0045],\n",
      "        [-0.0040,  0.0171,  0.0010,  ...,  0.0004, -0.0071, -0.0194]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       requires_grad=True))\n",
      "('features.11.conv.7.weight', Parameter containing:\n",
      "tensor([[[[ 0.2477]],\n",
      "\n",
      "         [[ 0.1791]],\n",
      "\n",
      "         [[ 0.1508]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0441]],\n",
      "\n",
      "         [[-0.1504]],\n",
      "\n",
      "         [[ 0.1911]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2460]],\n",
      "\n",
      "         [[-0.0171]],\n",
      "\n",
      "         [[-0.1282]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2726]],\n",
      "\n",
      "         [[-0.1118]],\n",
      "\n",
      "         [[ 0.1489]]],\n",
      "\n",
      "\n",
      "        [[[-0.0108]],\n",
      "\n",
      "         [[-0.1420]],\n",
      "\n",
      "         [[-0.3085]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0130]],\n",
      "\n",
      "         [[ 0.0692]],\n",
      "\n",
      "         [[ 0.0964]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0879]],\n",
      "\n",
      "         [[ 0.0729]],\n",
      "\n",
      "         [[-0.3656]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0006]],\n",
      "\n",
      "         [[ 0.2073]],\n",
      "\n",
      "         [[ 0.1650]]],\n",
      "\n",
      "\n",
      "        [[[-0.0696]],\n",
      "\n",
      "         [[ 0.1326]],\n",
      "\n",
      "         [[ 0.0756]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0873]],\n",
      "\n",
      "         [[ 0.1279]],\n",
      "\n",
      "         [[-0.3080]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0149]],\n",
      "\n",
      "         [[-0.2361]],\n",
      "\n",
      "         [[ 0.0373]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0051]],\n",
      "\n",
      "         [[-0.1901]],\n",
      "\n",
      "         [[-0.0940]]]], requires_grad=True))\n",
      "('features.11.conv.8.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1.], requires_grad=True))\n",
      "('features.11.conv.8.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       requires_grad=True))\n",
      "('features.12.0.weight', Parameter containing:\n",
      "tensor([[[[-0.1287]],\n",
      "\n",
      "         [[-0.0344]],\n",
      "\n",
      "         [[-0.0701]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0017]],\n",
      "\n",
      "         [[-0.0754]],\n",
      "\n",
      "         [[ 0.0619]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0938]],\n",
      "\n",
      "         [[-0.0335]],\n",
      "\n",
      "         [[-0.0048]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0009]],\n",
      "\n",
      "         [[ 0.0975]],\n",
      "\n",
      "         [[-0.1198]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0329]],\n",
      "\n",
      "         [[ 0.0456]],\n",
      "\n",
      "         [[ 0.0078]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0476]],\n",
      "\n",
      "         [[-0.0577]],\n",
      "\n",
      "         [[-0.0772]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0313]],\n",
      "\n",
      "         [[ 0.0148]],\n",
      "\n",
      "         [[-0.0120]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0270]],\n",
      "\n",
      "         [[-0.0048]],\n",
      "\n",
      "         [[-0.0167]]],\n",
      "\n",
      "\n",
      "        [[[-0.0405]],\n",
      "\n",
      "         [[ 0.0855]],\n",
      "\n",
      "         [[-0.1073]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0413]],\n",
      "\n",
      "         [[ 0.0168]],\n",
      "\n",
      "         [[-0.0105]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0174]],\n",
      "\n",
      "         [[ 0.0734]],\n",
      "\n",
      "         [[-0.0762]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0062]],\n",
      "\n",
      "         [[ 0.0007]],\n",
      "\n",
      "         [[ 0.0024]]]], requires_grad=True))\n",
      "('features.12.1.weight', Parameter containing:\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "       requires_grad=True))\n",
      "('features.12.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       requires_grad=True))\n",
      "('features.14.weight', Parameter containing:\n",
      "tensor([[[[-0.0174]],\n",
      "\n",
      "         [[-0.0624]],\n",
      "\n",
      "         [[-0.0354]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0695]],\n",
      "\n",
      "         [[-0.0150]],\n",
      "\n",
      "         [[ 0.0516]]],\n",
      "\n",
      "\n",
      "        [[[-0.0074]],\n",
      "\n",
      "         [[-0.0622]],\n",
      "\n",
      "         [[-0.0944]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0523]],\n",
      "\n",
      "         [[-0.0446]],\n",
      "\n",
      "         [[-0.0721]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0019]],\n",
      "\n",
      "         [[-0.0745]],\n",
      "\n",
      "         [[ 0.0013]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0372]],\n",
      "\n",
      "         [[ 0.0133]],\n",
      "\n",
      "         [[-0.0109]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0208]],\n",
      "\n",
      "         [[ 0.0012]],\n",
      "\n",
      "         [[-0.0979]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0177]],\n",
      "\n",
      "         [[-0.0274]],\n",
      "\n",
      "         [[-0.0285]]],\n",
      "\n",
      "\n",
      "        [[[-0.0182]],\n",
      "\n",
      "         [[ 0.0407]],\n",
      "\n",
      "         [[-0.0202]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0416]],\n",
      "\n",
      "         [[ 0.0203]],\n",
      "\n",
      "         [[ 0.0245]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0132]],\n",
      "\n",
      "         [[ 0.0306]],\n",
      "\n",
      "         [[-0.0222]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0165]],\n",
      "\n",
      "         [[-0.0213]],\n",
      "\n",
      "         [[-0.0031]]]], requires_grad=True))\n",
      "('features.14.bias', Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True))\n",
      "('classifier.1.weight', Parameter containing:\n",
      "tensor([[-0.0029,  0.0030,  0.0019,  ..., -0.0125,  0.0183,  0.0252],\n",
      "        [ 0.0079, -0.0024,  0.0056,  ...,  0.0156, -0.0176,  0.0102],\n",
      "        [ 0.0223, -0.0010, -0.0201,  ...,  0.0067, -0.0038, -0.0064],\n",
      "        ...,\n",
      "        [-0.0063, -0.0013, -0.0081,  ...,  0.0039, -0.0192,  0.0077],\n",
      "        [-0.0070, -0.0032,  0.0159,  ..., -0.0129, -0.0006,  0.0088],\n",
      "        [ 0.0054, -0.0045, -0.0187,  ...,  0.0096,  0.0046, -0.0004]],\n",
      "       requires_grad=True))\n",
      "('classifier.1.bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "for x in model.named_parameters():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'thop'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-224be0fb35a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'..'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_pipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_image_folders\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiagnostic\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtop_k_accuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount_params\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mentropy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_calibration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\trained-ternary-quantization\\utils\\diagnostic.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mthop\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'thop'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from math import ceil\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.input_pipeline import get_image_folders\n",
    "from utils.diagnostic import top_k_accuracy, count_params,\\\n",
    "    entropy, model_calibration, predict\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from get_mobilenet_v3 import get_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, val_folder = get_image_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, _, _ = get_model()\n",
    "\n",
    "# load pretrained quantized model\n",
    "model.load_state_dict(torch.load('model_ternary_quantization.pytorch_state'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "827784"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of params in the model\n",
    "count_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show quantized kernel tensors (there are 24 such kernels overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all quantized kernels    \n",
    "all_kernels = [\n",
    "    (n, p.data) for n, p in model.named_parameters()\n",
    "    if ('weight' in n and not 'bn' in n and not 'features.1.' in n \n",
    "        and not 'classifier' in n and not 'features.0.' in n)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+gAAALICAYAAADseNpmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09f6113e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(nrows=6, ncols=4, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "for i, (name, kernel) in enumerate(all_kernels):\n",
    "    axes[i].hist(kernel.cpu().numpy().reshape(-1));\n",
    "    axes[i].set_title(name[9:-7]);\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sparcity distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparcity = []\n",
    "for n, p in all_kernels:\n",
    "    sparcity.append(p.eq(0.0).float().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUoP+F/4YjlGFNJhgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09f6351e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sparcity);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66487083584070206"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(sparcity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scaling factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "upper_scaling_factor = []\n",
    "lower_scaling_factor = []\n",
    "for n, p in all_kernels:\n",
    "    upper_scaling_factor.append(p.max())\n",
    "    lower_scaling_factor.append(p.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJEO4ASAZwg0AyfwPYriPoLRBU3UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09f642afd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(upper_scaling_factor);\n",
    "plt.hist(lower_scaling_factor);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_iterator_no_shuffle = DataLoader(\n",
    "    val_folder, batch_size=64, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:10<00:00, 15.60it/s]\n"
     ]
    }
   ],
   "source": [
    "val_predictions, val_true_targets = predict(model, val_iterator_no_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logloss and accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8442614205883117"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(val_true_targets, val_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35570000000000002"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(val_true_targets, val_predictions.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47239999999999999, 0.54449999999999998, 0.59209999999999996, 0.62770000000000004, 0.73429999999999995]\n"
     ]
    }
   ],
   "source": [
    "print(top_k_accuracy(val_true_targets, val_predictions, k=(2, 3, 4, 5, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### number of misclassified images (there are overall 10000 images in the val dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6443"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hits = val_predictions.argmax(1) == val_true_targets\n",
    "(~hits).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### entropy of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEKCAYAAADpfBXhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7mZmGeTkbmaWQU7uZmYZ9P8BwJuIvJnqxekAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09f62bfc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(\n",
    "    entropy(val_predictions[hits]), bins=30, \n",
    "    normed=True, alpha=0.7, label='correct prediction'\n",
    ");\n",
    "plt.hist(\n",
    "    entropy(val_predictions[~hits]), bins=30, \n",
    "    normed=True, alpha=0.5, label='misclassification'\n",
    ");\n",
    "plt.legend();\n",
    "plt.xlabel('entropy of predictions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confidence of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEKCAYAAAAyx7/DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09f6246c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(\n",
    "    val_predictions[hits].max(1), bins=30, \n",
    "    normed=True, alpha=0.7, label='correct prediction'\n",
    ");\n",
    "plt.hist(\n",
    "    val_predictions[~hits].max(1), bins=30, \n",
    "    normed=True, alpha=0.5, label='misclassification'\n",
    ");\n",
    "plt.legend();\n",
    "plt.xlabel('confidence of predictions');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difference between biggest and second biggest probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEKCAYAAAAyx7/DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09f6846630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_correct = np.sort(val_predictions[hits], 1)\n",
    "sorted_incorrect = np.sort(val_predictions[~hits], 1)\n",
    "\n",
    "plt.hist(\n",
    "    sorted_correct[:, -1] - sorted_correct[:, -2], bins=30, \n",
    "    normed=True, alpha=0.7, label='correct prediction'\n",
    ");\n",
    "plt.hist(\n",
    "    sorted_incorrect[:, -1] - sorted_incorrect[:, -2], bins=30, \n",
    "    normed=True, alpha=0.5, label='misclassification'\n",
    ");\n",
    "plt.legend();\n",
    "plt.xlabel('difference');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### probabilistic calibration of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wEKzT4hyfEHNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09f6719748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_calibration(val_true_targets, val_predictions, n_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
